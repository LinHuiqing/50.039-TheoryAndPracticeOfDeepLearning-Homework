{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW11 - Descriptive Notebook\n",
    "\n",
    "Note: Updated, to remove flattening in trainer function.\n",
    "\n",
    "In this homework notebook, we will create a Wasserstein GAN with Convolution and Transpose Convolution layers, to be used on the MNIST dataset.\n",
    "\n",
    "Get familiar with the code and write a small report (2 pages max), with answers to the questions listed at the end of the notebook.\n",
    "\n",
    "**The report must be submitted in PDF format, before April 18th, 11.59pm!**\n",
    "\n",
    "Do not forget to write your name and student ID on the report.\n",
    "\n",
    "You may also submit your own copy of the notebook along with the report. If you do so, please add your name and ID to the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name: Lin Huiqiqng\n",
    "# Student ID: 1003810"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch import Tensor\n",
    "from torch.autograd import Variable\n",
    "import torch.autograd as autograd\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image transform to be applied to dataset\n",
    "# - Tensor conversion\n",
    "transform = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST train dataset\n",
    "mnist = torchvision.datasets.MNIST(root = './data/',\n",
    "                                   train = True,\n",
    "                                   transform = transform,\n",
    "                                   download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "batch_size = 32\n",
    "data_loader = torch.utils.data.DataLoader(dataset = mnist,\n",
    "                                          batch_size = batch_size, \n",
    "                                          shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Critic model as a set of Conv2d layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task1:** Rewrite the Critic model below, so that it uses Conv2d layers instead of fully connected ones shown in class.\n",
    "\n",
    "You may look for inspiration in the encoder models used in Notebook 3 (W11S1 lecture).\n",
    "\n",
    "The critic should use three Conv2d layers with progressive downsampling.\n",
    "\n",
    "We do not advise to add more layers to the mix (BatchNorm, Dropout, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Critic\n",
    "class Critic(nn.Module):\n",
    "    \n",
    "    def __init__(self, image_size):\n",
    "        \"\"\"\n",
    "        Only forced parameter will be the image size, set to 28.\n",
    "        \"\"\"\n",
    "        super(Critic, self).__init__()\n",
    "        std_kern_size = image_size // 3\n",
    "        final_kern_size = image_size - 2 * std_kern_size\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(1, 64, std_kern_size+1)\n",
    "        self.conv2 = torch.nn.Conv2d(64, 64, std_kern_size+1)\n",
    "        self.conv3 = torch.nn.Conv2d(64, 1, final_kern_size)\n",
    "        \n",
    "        self.leaky_relu = torch.nn.LeakyReLU(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator model as a set of Transposed Conv2d layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task2:** Rewrite the Generator model below, so that it uses Transposed Conv2d layers instead of fully connected ones shown in class.\n",
    "\n",
    "You may look for inspiration in the encoder models used in Notebooks 2 and 3 (W11S1 lecture).\n",
    "\n",
    "The critic should use three Transposed Conv2d layers with progressive upsampling.\n",
    "\n",
    "We do not advise to add more layers to the mix (BatchNorm, Dropout, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, latent_size, image_size):\n",
    "        \"\"\"\n",
    "        Only forced parameters will be the image size, set to 28,\n",
    "        and the latent size set to 64.\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "        std_kern_size = image_size // 3\n",
    "        final_kern_size = image_size - 2 * std_kern_size\n",
    "\n",
    "        self.transconv1 = torch.nn.ConvTranspose2d(latent_size, 64, std_kern_size)\n",
    "        self.transconv2 = torch.nn.ConvTranspose2d(64, 64, std_kern_size)\n",
    "        self.transconv3 = torch.nn.ConvTranspose2d(64, 1, final_kern_size)\n",
    "\n",
    "        self.leaky_relu = torch.nn.LeakyReLU()\n",
    "        self.tanh = torch.nn.Tanh()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.transconv1(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.transconv2(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.transconv3(x)\n",
    "        x = self.tanh(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer function\n",
    "\n",
    "**Task 3:** Decide on a number of iterations num_epochs for training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for model generation and training\n",
    "latent_size = 64\n",
    "image_size = 28\n",
    "num_epochs = 300\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Critic(\n  (conv1): Conv2d(1, 64, kernel_size=(10, 10), stride=(1, 1))\n  (conv2): Conv2d(64, 64, kernel_size=(10, 10), stride=(1, 1))\n  (conv3): Conv2d(64, 1, kernel_size=(10, 10), stride=(1, 1))\n  (leaky_relu): LeakyReLU(negative_slope=0.2)\n)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create discriminator model\n",
    "f = Critic(image_size)\n",
    "f.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Generator(\n  (transconv1): ConvTranspose2d(64, 64, kernel_size=(9, 9), stride=(1, 1))\n  (transconv2): ConvTranspose2d(64, 64, kernel_size=(9, 9), stride=(1, 1))\n  (transconv3): ConvTranspose2d(64, 1, kernel_size=(10, 10), stride=(1, 1))\n  (leaky_relu): LeakyReLU(negative_slope=0.01)\n  (tanh): Tanh()\n)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create generator model\n",
    "G = Generator(latent_size, image_size)\n",
    "G.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses and optimizers\n",
    "d_optimizer = torch.optim.RMSprop(f.parameters(), lr = 0.00005)\n",
    "g_optimizer = torch.optim.RMSprop(G.parameters(), lr = 0.00005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# History trackers for training curves\n",
    "# Keeping track of losses\n",
    "d_losses = np.zeros(num_epochs)\n",
    "g_losses = np.zeros(num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: running the cell below (our trainer function) will take a long time!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_grid_col = 8\n",
    "img_grid_row = 4\n",
    "\n",
    "gen_train_no = 5\n",
    "\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Step [200/1875], d_loss: -0.0829, g_loss: 0.1294\n",
      "Epoch [1/300], Step [400/1875], d_loss: -0.0562, g_loss: 0.0736\n",
      "Epoch [1/300], Step [600/1875], d_loss: -0.3179, g_loss: -0.6107\n",
      "Epoch [1/300], Step [800/1875], d_loss: -0.8017, g_loss: -1.3853\n",
      "Epoch [1/300], Step [1000/1875], d_loss: -1.1739, g_loss: 0.3814\n",
      "Epoch [1/300], Step [1200/1875], d_loss: -0.9654, g_loss: 0.1008\n",
      "Epoch [1/300], Step [1400/1875], d_loss: -1.1932, g_loss: 0.0208\n",
      "Epoch [1/300], Step [1600/1875], d_loss: -1.0118, g_loss: -0.1896\n",
      "Epoch [1/300], Step [1800/1875], d_loss: -0.9058, g_loss: 1.0607\n",
      "Epoch [2/300], Step [200/1875], d_loss: -0.9634, g_loss: 0.7539\n",
      "Epoch [2/300], Step [400/1875], d_loss: -0.8699, g_loss: -0.8759\n",
      "Epoch [2/300], Step [600/1875], d_loss: -0.8683, g_loss: 1.3576\n",
      "Epoch [2/300], Step [800/1875], d_loss: -0.5306, g_loss: 0.4275\n",
      "Epoch [2/300], Step [1000/1875], d_loss: -1.0904, g_loss: 1.9448\n",
      "Epoch [2/300], Step [1200/1875], d_loss: -0.8255, g_loss: -1.3646\n",
      "Epoch [2/300], Step [1400/1875], d_loss: -0.7369, g_loss: -0.6670\n",
      "Epoch [2/300], Step [1600/1875], d_loss: -0.9121, g_loss: 0.4370\n",
      "Epoch [2/300], Step [1800/1875], d_loss: -0.8714, g_loss: -1.6110\n",
      "Epoch [3/300], Step [200/1875], d_loss: -0.7037, g_loss: -0.3046\n",
      "Epoch [3/300], Step [400/1875], d_loss: -0.6393, g_loss: -0.3702\n",
      "Epoch [3/300], Step [600/1875], d_loss: -0.3832, g_loss: -0.8318\n",
      "Epoch [3/300], Step [800/1875], d_loss: -0.6346, g_loss: -1.1923\n",
      "Epoch [3/300], Step [1000/1875], d_loss: -0.4285, g_loss: 0.0921\n",
      "Epoch [3/300], Step [1200/1875], d_loss: -0.4374, g_loss: 1.0196\n",
      "Epoch [3/300], Step [1400/1875], d_loss: -0.5739, g_loss: 0.2022\n",
      "Epoch [3/300], Step [1600/1875], d_loss: -0.4644, g_loss: -0.3919\n",
      "Epoch [3/300], Step [1800/1875], d_loss: -0.5757, g_loss: -0.7978\n",
      "Epoch [4/300], Step [200/1875], d_loss: -0.2673, g_loss: 3.3960\n",
      "Epoch [4/300], Step [400/1875], d_loss: -0.4681, g_loss: 1.2842\n",
      "Epoch [4/300], Step [600/1875], d_loss: -0.5389, g_loss: 1.8500\n",
      "Epoch [4/300], Step [800/1875], d_loss: -0.3986, g_loss: -0.1817\n",
      "Epoch [4/300], Step [1000/1875], d_loss: -0.3820, g_loss: -0.6096\n",
      "Epoch [4/300], Step [1200/1875], d_loss: -0.5052, g_loss: 0.0607\n",
      "Epoch [4/300], Step [1400/1875], d_loss: -0.4153, g_loss: 0.6159\n",
      "Epoch [4/300], Step [1600/1875], d_loss: -0.6095, g_loss: 0.3000\n",
      "Epoch [4/300], Step [1800/1875], d_loss: -0.5313, g_loss: -0.9938\n",
      "Epoch [5/300], Step [200/1875], d_loss: -0.2821, g_loss: 0.7714\n",
      "Epoch [5/300], Step [400/1875], d_loss: -0.5984, g_loss: -0.4812\n",
      "Epoch [5/300], Step [600/1875], d_loss: -0.6182, g_loss: -0.8495\n",
      "Epoch [5/300], Step [800/1875], d_loss: -0.4140, g_loss: -0.6770\n",
      "Epoch [5/300], Step [1000/1875], d_loss: -0.1269, g_loss: 2.3318\n",
      "Epoch [5/300], Step [1200/1875], d_loss: -0.3673, g_loss: 0.4071\n",
      "Epoch [5/300], Step [1400/1875], d_loss: -0.5532, g_loss: -0.7288\n",
      "Epoch [5/300], Step [1600/1875], d_loss: -0.4420, g_loss: -0.2278\n",
      "Epoch [5/300], Step [1800/1875], d_loss: -0.4062, g_loss: 1.5603\n",
      "Epoch [6/300], Step [200/1875], d_loss: -0.5774, g_loss: -0.3955\n",
      "Epoch [6/300], Step [400/1875], d_loss: -0.5715, g_loss: -1.3333\n",
      "Epoch [6/300], Step [600/1875], d_loss: -0.4271, g_loss: 1.4983\n",
      "Epoch [6/300], Step [800/1875], d_loss: 0.0952, g_loss: -1.7633\n",
      "Epoch [6/300], Step [1000/1875], d_loss: -0.4583, g_loss: 0.8861\n",
      "Epoch [6/300], Step [1200/1875], d_loss: -0.4611, g_loss: 0.1001\n",
      "Epoch [6/300], Step [1400/1875], d_loss: -0.5031, g_loss: -0.6120\n",
      "Epoch [6/300], Step [1600/1875], d_loss: -0.4386, g_loss: 0.5176\n",
      "Epoch [6/300], Step [1800/1875], d_loss: -0.5941, g_loss: 2.1141\n",
      "Epoch [7/300], Step [200/1875], d_loss: -0.3332, g_loss: -1.2906\n",
      "Epoch [7/300], Step [400/1875], d_loss: -0.4560, g_loss: 0.4742\n",
      "Epoch [7/300], Step [600/1875], d_loss: -0.4957, g_loss: -0.2219\n",
      "Epoch [7/300], Step [800/1875], d_loss: -0.5093, g_loss: -0.8898\n",
      "Epoch [7/300], Step [1000/1875], d_loss: -0.4944, g_loss: -0.6903\n",
      "Epoch [7/300], Step [1200/1875], d_loss: -0.4295, g_loss: -0.3203\n",
      "Epoch [7/300], Step [1400/1875], d_loss: -0.2378, g_loss: 0.5644\n",
      "Epoch [7/300], Step [1600/1875], d_loss: -0.5144, g_loss: -2.3373\n",
      "Epoch [7/300], Step [1800/1875], d_loss: -0.4299, g_loss: 0.3484\n",
      "Epoch [8/300], Step [200/1875], d_loss: -0.3888, g_loss: -1.0173\n",
      "Epoch [8/300], Step [400/1875], d_loss: -0.4039, g_loss: 1.5061\n",
      "Epoch [8/300], Step [600/1875], d_loss: -0.5504, g_loss: 1.4758\n",
      "Epoch [8/300], Step [800/1875], d_loss: -0.3903, g_loss: 2.6162\n",
      "Epoch [8/300], Step [1000/1875], d_loss: -0.4657, g_loss: -1.7790\n",
      "Epoch [8/300], Step [1200/1875], d_loss: -0.4522, g_loss: -0.7882\n",
      "Epoch [8/300], Step [1400/1875], d_loss: -0.3394, g_loss: -0.0239\n",
      "Epoch [8/300], Step [1600/1875], d_loss: -0.5373, g_loss: -1.3330\n",
      "Epoch [8/300], Step [1800/1875], d_loss: -0.1913, g_loss: 2.0324\n",
      "Epoch [9/300], Step [200/1875], d_loss: -0.4857, g_loss: 0.4240\n",
      "Epoch [9/300], Step [400/1875], d_loss: -0.4017, g_loss: -1.6421\n",
      "Epoch [9/300], Step [600/1875], d_loss: -0.3880, g_loss: 1.2459\n",
      "Epoch [9/300], Step [800/1875], d_loss: -0.3042, g_loss: -0.7271\n",
      "Epoch [9/300], Step [1000/1875], d_loss: -0.4768, g_loss: 1.4934\n",
      "Epoch [9/300], Step [1200/1875], d_loss: -0.3742, g_loss: 0.4925\n",
      "Epoch [9/300], Step [1400/1875], d_loss: -0.7015, g_loss: 2.7039\n",
      "Epoch [9/300], Step [1600/1875], d_loss: -0.3529, g_loss: -0.0688\n",
      "Epoch [9/300], Step [1800/1875], d_loss: -0.3554, g_loss: 0.5815\n",
      "Epoch [10/300], Step [200/1875], d_loss: -0.1550, g_loss: -0.0822\n",
      "Epoch [10/300], Step [400/1875], d_loss: -0.2711, g_loss: -0.6250\n",
      "Epoch [10/300], Step [600/1875], d_loss: -0.3991, g_loss: 0.0798\n",
      "Epoch [10/300], Step [800/1875], d_loss: -0.4638, g_loss: 1.2875\n",
      "Epoch [10/300], Step [1000/1875], d_loss: -0.4405, g_loss: 0.0114\n",
      "Epoch [10/300], Step [1200/1875], d_loss: -0.3269, g_loss: 1.6470\n",
      "Epoch [10/300], Step [1400/1875], d_loss: -0.3155, g_loss: -1.6252\n",
      "Epoch [10/300], Step [1600/1875], d_loss: -0.3347, g_loss: -0.2289\n",
      "Epoch [10/300], Step [1800/1875], d_loss: -0.3534, g_loss: 1.1600\n",
      "Epoch [11/300], Step [200/1875], d_loss: -0.3552, g_loss: -1.1660\n",
      "Epoch [11/300], Step [400/1875], d_loss: -0.3099, g_loss: -0.8006\n",
      "Epoch [11/300], Step [600/1875], d_loss: -0.4592, g_loss: 1.4794\n",
      "Epoch [11/300], Step [800/1875], d_loss: -0.3952, g_loss: -0.6674\n",
      "Epoch [11/300], Step [1000/1875], d_loss: -0.4331, g_loss: 1.5537\n",
      "Epoch [11/300], Step [1200/1875], d_loss: -0.2326, g_loss: -2.1437\n",
      "Epoch [11/300], Step [1400/1875], d_loss: -0.3551, g_loss: -0.5538\n",
      "Epoch [11/300], Step [1600/1875], d_loss: -0.3727, g_loss: -1.9465\n",
      "Epoch [11/300], Step [1800/1875], d_loss: -0.2279, g_loss: -1.4212\n",
      "Epoch [12/300], Step [200/1875], d_loss: -0.3570, g_loss: 1.2768\n",
      "Epoch [12/300], Step [400/1875], d_loss: -0.3363, g_loss: -1.2092\n",
      "Epoch [12/300], Step [600/1875], d_loss: -0.3800, g_loss: 0.0230\n",
      "Epoch [12/300], Step [800/1875], d_loss: -0.4054, g_loss: -0.0805\n",
      "Epoch [12/300], Step [1000/1875], d_loss: -0.3263, g_loss: 1.0813\n",
      "Epoch [12/300], Step [1200/1875], d_loss: -0.3013, g_loss: -0.6713\n",
      "Epoch [12/300], Step [1400/1875], d_loss: -0.2832, g_loss: -1.0354\n",
      "Epoch [12/300], Step [1600/1875], d_loss: -0.3587, g_loss: 0.0973\n",
      "Epoch [12/300], Step [1800/1875], d_loss: -0.4019, g_loss: 1.5560\n",
      "Epoch [13/300], Step [200/1875], d_loss: -0.2181, g_loss: -0.3886\n",
      "Epoch [13/300], Step [400/1875], d_loss: -0.4612, g_loss: 2.2811\n",
      "Epoch [13/300], Step [600/1875], d_loss: -0.3093, g_loss: 0.4070\n",
      "Epoch [13/300], Step [800/1875], d_loss: -0.1031, g_loss: -0.9561\n",
      "Epoch [13/300], Step [1000/1875], d_loss: -0.3057, g_loss: -0.7840\n",
      "Epoch [13/300], Step [1200/1875], d_loss: -0.1645, g_loss: -1.0953\n",
      "Epoch [13/300], Step [1400/1875], d_loss: -0.3994, g_loss: -3.0486\n",
      "Epoch [13/300], Step [1600/1875], d_loss: -0.3289, g_loss: -2.2387\n",
      "Epoch [13/300], Step [1800/1875], d_loss: -0.2227, g_loss: -1.3145\n",
      "Epoch [14/300], Step [200/1875], d_loss: -0.2803, g_loss: -2.4497\n",
      "Epoch [14/300], Step [400/1875], d_loss: -0.2319, g_loss: 0.2939\n",
      "Epoch [14/300], Step [600/1875], d_loss: -0.2311, g_loss: -0.9132\n",
      "Epoch [14/300], Step [800/1875], d_loss: -0.2464, g_loss: -0.5384\n",
      "Epoch [14/300], Step [1000/1875], d_loss: -0.4939, g_loss: -3.0830\n",
      "Epoch [14/300], Step [1200/1875], d_loss: -0.3516, g_loss: -0.6770\n",
      "Epoch [14/300], Step [1400/1875], d_loss: 0.0117, g_loss: -0.1292\n",
      "Epoch [14/300], Step [1600/1875], d_loss: -0.2757, g_loss: -2.2195\n",
      "Epoch [14/300], Step [1800/1875], d_loss: -0.0699, g_loss: -0.4183\n",
      "Epoch [15/300], Step [200/1875], d_loss: -0.0285, g_loss: -2.2546\n",
      "Epoch [15/300], Step [400/1875], d_loss: -0.3796, g_loss: 0.9491\n",
      "Epoch [15/300], Step [600/1875], d_loss: -0.1516, g_loss: 0.0693\n",
      "Epoch [15/300], Step [800/1875], d_loss: -0.2813, g_loss: 1.0487\n",
      "Epoch [15/300], Step [1000/1875], d_loss: -0.3821, g_loss: -0.9679\n",
      "Epoch [15/300], Step [1200/1875], d_loss: -0.1566, g_loss: -0.3881\n",
      "Epoch [15/300], Step [1400/1875], d_loss: -0.1420, g_loss: -0.7546\n",
      "Epoch [15/300], Step [1600/1875], d_loss: -0.2430, g_loss: -1.0140\n",
      "Epoch [15/300], Step [1800/1875], d_loss: -0.2031, g_loss: -0.5802\n",
      "Epoch [16/300], Step [200/1875], d_loss: -0.2933, g_loss: -0.8454\n",
      "Epoch [16/300], Step [400/1875], d_loss: -0.2907, g_loss: -0.1146\n",
      "Epoch [16/300], Step [600/1875], d_loss: -0.2847, g_loss: -0.4056\n",
      "Epoch [16/300], Step [800/1875], d_loss: -0.0700, g_loss: -1.9411\n",
      "Epoch [16/300], Step [1000/1875], d_loss: -0.2620, g_loss: -3.2873\n",
      "Epoch [16/300], Step [1200/1875], d_loss: -0.1315, g_loss: 0.6116\n",
      "Epoch [16/300], Step [1400/1875], d_loss: -0.0813, g_loss: -1.0398\n",
      "Epoch [16/300], Step [1600/1875], d_loss: -0.2623, g_loss: -0.2330\n",
      "Epoch [16/300], Step [1800/1875], d_loss: -0.0945, g_loss: -0.6426\n",
      "Epoch [17/300], Step [200/1875], d_loss: -0.3258, g_loss: 1.5917\n",
      "Epoch [17/300], Step [400/1875], d_loss: -0.1623, g_loss: 0.9231\n",
      "Epoch [17/300], Step [600/1875], d_loss: -0.2687, g_loss: -1.7005\n",
      "Epoch [17/300], Step [800/1875], d_loss: -0.2530, g_loss: 0.3449\n",
      "Epoch [17/300], Step [1000/1875], d_loss: -0.1889, g_loss: -1.2120\n",
      "Epoch [17/300], Step [1200/1875], d_loss: -0.2170, g_loss: -1.6253\n",
      "Epoch [17/300], Step [1400/1875], d_loss: -0.2394, g_loss: -0.3251\n",
      "Epoch [17/300], Step [1600/1875], d_loss: -0.2685, g_loss: -2.6396\n",
      "Epoch [17/300], Step [1800/1875], d_loss: -0.2252, g_loss: -1.4804\n",
      "Epoch [18/300], Step [200/1875], d_loss: -0.2414, g_loss: -0.1910\n",
      "Epoch [18/300], Step [400/1875], d_loss: -0.1659, g_loss: -1.0843\n",
      "Epoch [18/300], Step [600/1875], d_loss: -0.3553, g_loss: 0.9413\n",
      "Epoch [18/300], Step [800/1875], d_loss: -0.2732, g_loss: -1.1315\n",
      "Epoch [18/300], Step [1000/1875], d_loss: 0.0029, g_loss: -0.6166\n",
      "Epoch [18/300], Step [1200/1875], d_loss: -0.2859, g_loss: -0.8651\n",
      "Epoch [18/300], Step [1400/1875], d_loss: -0.0981, g_loss: -0.8218\n",
      "Epoch [18/300], Step [1600/1875], d_loss: -0.1896, g_loss: -0.5336\n",
      "Epoch [18/300], Step [1800/1875], d_loss: -0.2514, g_loss: -0.4379\n",
      "Epoch [19/300], Step [200/1875], d_loss: -0.3062, g_loss: -0.4899\n",
      "Epoch [19/300], Step [400/1875], d_loss: -0.3525, g_loss: 0.5233\n",
      "Epoch [19/300], Step [600/1875], d_loss: -0.3285, g_loss: -2.3847\n",
      "Epoch [19/300], Step [800/1875], d_loss: -0.2222, g_loss: -2.1145\n",
      "Epoch [19/300], Step [1000/1875], d_loss: -0.1121, g_loss: -0.4782\n",
      "Epoch [19/300], Step [1200/1875], d_loss: -0.0760, g_loss: 0.4206\n",
      "Epoch [19/300], Step [1400/1875], d_loss: -0.2412, g_loss: -1.3034\n",
      "Epoch [19/300], Step [1600/1875], d_loss: -0.3368, g_loss: -0.7090\n",
      "Epoch [19/300], Step [1800/1875], d_loss: -0.1855, g_loss: -1.0533\n",
      "Epoch [20/300], Step [200/1875], d_loss: -0.0452, g_loss: -0.6789\n",
      "Epoch [20/300], Step [400/1875], d_loss: -0.2334, g_loss: 0.4595\n",
      "Epoch [20/300], Step [600/1875], d_loss: -0.2946, g_loss: -0.5206\n",
      "Epoch [20/300], Step [800/1875], d_loss: -0.2682, g_loss: -0.4968\n",
      "Epoch [20/300], Step [1000/1875], d_loss: -0.3352, g_loss: 0.7763\n",
      "Epoch [20/300], Step [1200/1875], d_loss: -0.2328, g_loss: -0.0550\n",
      "Epoch [20/300], Step [1400/1875], d_loss: -0.2039, g_loss: -0.4565\n",
      "Epoch [20/300], Step [1600/1875], d_loss: -0.1377, g_loss: -0.4403\n",
      "Epoch [20/300], Step [1800/1875], d_loss: -0.4074, g_loss: -0.9388\n",
      "Epoch [21/300], Step [200/1875], d_loss: -0.2507, g_loss: -0.3266\n",
      "Epoch [21/300], Step [400/1875], d_loss: -0.2704, g_loss: 0.4893\n",
      "Epoch [21/300], Step [600/1875], d_loss: -0.1712, g_loss: -1.4038\n",
      "Epoch [21/300], Step [800/1875], d_loss: -0.2784, g_loss: 0.8447\n",
      "Epoch [21/300], Step [1000/1875], d_loss: -0.3411, g_loss: -1.2752\n",
      "Epoch [21/300], Step [1200/1875], d_loss: -0.2410, g_loss: 1.0044\n",
      "Epoch [21/300], Step [1400/1875], d_loss: -0.2244, g_loss: -1.6747\n",
      "Epoch [21/300], Step [1600/1875], d_loss: -0.0398, g_loss: 1.3379\n",
      "Epoch [21/300], Step [1800/1875], d_loss: -0.2799, g_loss: 0.2940\n",
      "Epoch [22/300], Step [200/1875], d_loss: -0.1228, g_loss: -1.9795\n",
      "Epoch [22/300], Step [400/1875], d_loss: -0.2710, g_loss: 1.1380\n",
      "Epoch [22/300], Step [600/1875], d_loss: -0.2464, g_loss: -1.9212\n",
      "Epoch [22/300], Step [800/1875], d_loss: -0.2444, g_loss: -2.4532\n",
      "Epoch [22/300], Step [1000/1875], d_loss: -0.2544, g_loss: 1.1490\n",
      "Epoch [22/300], Step [1200/1875], d_loss: -0.2868, g_loss: -2.9838\n",
      "Epoch [22/300], Step [1400/1875], d_loss: -0.2280, g_loss: -1.3107\n",
      "Epoch [22/300], Step [1600/1875], d_loss: -0.2646, g_loss: 1.9714\n",
      "Epoch [22/300], Step [1800/1875], d_loss: -0.2509, g_loss: -0.5874\n",
      "Epoch [23/300], Step [200/1875], d_loss: -0.2204, g_loss: -0.3557\n",
      "Epoch [23/300], Step [400/1875], d_loss: -0.1590, g_loss: 1.4698\n",
      "Epoch [23/300], Step [600/1875], d_loss: -0.3359, g_loss: -1.2341\n",
      "Epoch [23/300], Step [800/1875], d_loss: -0.0274, g_loss: -1.5211\n",
      "Epoch [23/300], Step [1000/1875], d_loss: -0.0198, g_loss: 0.2317\n",
      "Epoch [23/300], Step [1200/1875], d_loss: -0.0493, g_loss: -0.3748\n",
      "Epoch [23/300], Step [1400/1875], d_loss: -0.1449, g_loss: -0.5676\n",
      "Epoch [23/300], Step [1600/1875], d_loss: 0.2654, g_loss: 0.0721\n",
      "Epoch [23/300], Step [1800/1875], d_loss: -0.2286, g_loss: 0.3101\n",
      "Epoch [24/300], Step [200/1875], d_loss: -0.2524, g_loss: 0.7724\n",
      "Epoch [24/300], Step [400/1875], d_loss: -0.1694, g_loss: -0.9491\n",
      "Epoch [24/300], Step [600/1875], d_loss: -0.0224, g_loss: -1.2220\n",
      "Epoch [24/300], Step [800/1875], d_loss: -0.2604, g_loss: -0.5753\n",
      "Epoch [24/300], Step [1000/1875], d_loss: -0.2559, g_loss: -0.5742\n",
      "Epoch [24/300], Step [1200/1875], d_loss: -0.1958, g_loss: 0.2620\n",
      "Epoch [24/300], Step [1400/1875], d_loss: -0.3172, g_loss: -0.0133\n",
      "Epoch [24/300], Step [1600/1875], d_loss: -0.2494, g_loss: 0.0562\n",
      "Epoch [24/300], Step [1800/1875], d_loss: -0.2334, g_loss: -0.3239\n",
      "Epoch [25/300], Step [200/1875], d_loss: -0.3047, g_loss: 1.2705\n",
      "Epoch [25/300], Step [400/1875], d_loss: -0.2156, g_loss: 0.4402\n",
      "Epoch [25/300], Step [600/1875], d_loss: -0.2056, g_loss: 0.5655\n",
      "Epoch [25/300], Step [800/1875], d_loss: -0.2861, g_loss: -0.2187\n",
      "Epoch [25/300], Step [1000/1875], d_loss: -0.1785, g_loss: -0.6907\n",
      "Epoch [25/300], Step [1200/1875], d_loss: -0.0179, g_loss: -1.4144\n",
      "Epoch [25/300], Step [1400/1875], d_loss: -0.1638, g_loss: -0.0034\n",
      "Epoch [25/300], Step [1600/1875], d_loss: -0.3474, g_loss: 0.9790\n",
      "Epoch [25/300], Step [1800/1875], d_loss: -0.3446, g_loss: 1.6087\n",
      "Epoch [26/300], Step [200/1875], d_loss: -0.1454, g_loss: -1.6674\n",
      "Epoch [26/300], Step [400/1875], d_loss: 0.0908, g_loss: -1.3498\n",
      "Epoch [26/300], Step [600/1875], d_loss: -0.2909, g_loss: -1.1819\n",
      "Epoch [26/300], Step [800/1875], d_loss: -0.2061, g_loss: -1.4007\n",
      "Epoch [26/300], Step [1000/1875], d_loss: -0.2591, g_loss: -0.2843\n",
      "Epoch [26/300], Step [1200/1875], d_loss: -0.2983, g_loss: -1.8681\n",
      "Epoch [26/300], Step [1400/1875], d_loss: -0.1406, g_loss: -0.7198\n",
      "Epoch [26/300], Step [1600/1875], d_loss: -0.1576, g_loss: -2.2337\n",
      "Epoch [26/300], Step [1800/1875], d_loss: -0.2022, g_loss: 0.1704\n",
      "Epoch [27/300], Step [200/1875], d_loss: -0.1975, g_loss: -0.8093\n",
      "Epoch [27/300], Step [400/1875], d_loss: -0.1845, g_loss: -1.1050\n",
      "Epoch [27/300], Step [600/1875], d_loss: 0.1270, g_loss: -0.7647\n",
      "Epoch [27/300], Step [800/1875], d_loss: -0.1788, g_loss: -2.1278\n",
      "Epoch [27/300], Step [1000/1875], d_loss: -0.0037, g_loss: -0.9754\n",
      "Epoch [27/300], Step [1200/1875], d_loss: -0.0715, g_loss: 0.0184\n",
      "Epoch [27/300], Step [1400/1875], d_loss: -0.2310, g_loss: -0.7640\n",
      "Epoch [27/300], Step [1600/1875], d_loss: -0.1740, g_loss: 0.1849\n",
      "Epoch [27/300], Step [1800/1875], d_loss: -0.3084, g_loss: 2.5109\n",
      "Epoch [28/300], Step [200/1875], d_loss: -0.1266, g_loss: -1.4983\n",
      "Epoch [28/300], Step [400/1875], d_loss: -0.4183, g_loss: -2.6150\n",
      "Epoch [28/300], Step [600/1875], d_loss: -0.2135, g_loss: -0.8465\n",
      "Epoch [28/300], Step [800/1875], d_loss: -0.2485, g_loss: 0.8958\n",
      "Epoch [28/300], Step [1000/1875], d_loss: -0.2385, g_loss: -1.0715\n",
      "Epoch [28/300], Step [1200/1875], d_loss: -0.2015, g_loss: 1.0222\n",
      "Epoch [28/300], Step [1400/1875], d_loss: -0.2348, g_loss: -1.5317\n",
      "Epoch [28/300], Step [1600/1875], d_loss: -0.2168, g_loss: -1.4380\n",
      "Epoch [28/300], Step [1800/1875], d_loss: -0.3004, g_loss: -1.9436\n",
      "Epoch [29/300], Step [200/1875], d_loss: -0.1712, g_loss: -0.5069\n",
      "Epoch [29/300], Step [400/1875], d_loss: -0.3221, g_loss: 0.3708\n",
      "Epoch [29/300], Step [600/1875], d_loss: -0.3401, g_loss: -2.7822\n",
      "Epoch [29/300], Step [800/1875], d_loss: -0.2577, g_loss: -1.3137\n",
      "Epoch [29/300], Step [1000/1875], d_loss: -0.1266, g_loss: -0.5754\n",
      "Epoch [29/300], Step [1200/1875], d_loss: -0.2971, g_loss: -0.1484\n",
      "Epoch [29/300], Step [1400/1875], d_loss: -0.0732, g_loss: -0.7581\n",
      "Epoch [29/300], Step [1600/1875], d_loss: -0.1943, g_loss: -1.3002\n",
      "Epoch [29/300], Step [1800/1875], d_loss: -0.1964, g_loss: 0.0197\n",
      "Epoch [30/300], Step [200/1875], d_loss: -0.1675, g_loss: -0.6095\n",
      "Epoch [30/300], Step [400/1875], d_loss: -0.1843, g_loss: -2.8586\n",
      "Epoch [30/300], Step [600/1875], d_loss: -0.1216, g_loss: -0.8135\n",
      "Epoch [30/300], Step [800/1875], d_loss: -0.2383, g_loss: 0.5724\n",
      "Epoch [30/300], Step [1000/1875], d_loss: -0.1198, g_loss: 0.9580\n",
      "Epoch [30/300], Step [1200/1875], d_loss: -0.1790, g_loss: 0.1681\n",
      "Epoch [30/300], Step [1400/1875], d_loss: -0.2796, g_loss: -2.8077\n",
      "Epoch [30/300], Step [1600/1875], d_loss: -0.1228, g_loss: 1.7456\n",
      "Epoch [30/300], Step [1800/1875], d_loss: -0.1591, g_loss: -1.2971\n",
      "Epoch [31/300], Step [200/1875], d_loss: -0.0931, g_loss: -0.9196\n",
      "Epoch [31/300], Step [400/1875], d_loss: -0.2104, g_loss: -0.1427\n",
      "Epoch [31/300], Step [600/1875], d_loss: -0.2934, g_loss: -2.7614\n",
      "Epoch [31/300], Step [800/1875], d_loss: -0.2254, g_loss: -1.8047\n",
      "Epoch [31/300], Step [1000/1875], d_loss: -0.0365, g_loss: -1.1833\n",
      "Epoch [31/300], Step [1200/1875], d_loss: -0.1712, g_loss: -0.8536\n",
      "Epoch [31/300], Step [1400/1875], d_loss: -0.1005, g_loss: -0.5842\n",
      "Epoch [31/300], Step [1600/1875], d_loss: -0.2075, g_loss: -1.3082\n",
      "Epoch [31/300], Step [1800/1875], d_loss: -0.3624, g_loss: -2.3142\n",
      "Epoch [32/300], Step [200/1875], d_loss: -0.1327, g_loss: -1.0880\n",
      "Epoch [32/300], Step [400/1875], d_loss: -0.2413, g_loss: 0.3054\n",
      "Epoch [32/300], Step [600/1875], d_loss: -0.0885, g_loss: -0.7715\n",
      "Epoch [32/300], Step [800/1875], d_loss: -0.0848, g_loss: -2.2765\n",
      "Epoch [32/300], Step [1000/1875], d_loss: -0.0043, g_loss: -0.0165\n",
      "Epoch [32/300], Step [1200/1875], d_loss: -0.3137, g_loss: -2.8808\n",
      "Epoch [32/300], Step [1400/1875], d_loss: -0.1443, g_loss: 0.1565\n",
      "Epoch [32/300], Step [1600/1875], d_loss: -0.1098, g_loss: -1.8127\n",
      "Epoch [32/300], Step [1800/1875], d_loss: -0.0240, g_loss: -0.9588\n",
      "Epoch [33/300], Step [200/1875], d_loss: -0.1985, g_loss: 0.1625\n",
      "Epoch [33/300], Step [400/1875], d_loss: -0.4192, g_loss: -1.7950\n",
      "Epoch [33/300], Step [600/1875], d_loss: -0.1587, g_loss: -2.3808\n",
      "Epoch [33/300], Step [800/1875], d_loss: -0.0951, g_loss: -1.8962\n",
      "Epoch [33/300], Step [1000/1875], d_loss: -0.1646, g_loss: 0.1766\n",
      "Epoch [33/300], Step [1200/1875], d_loss: -0.2220, g_loss: -0.0659\n",
      "Epoch [33/300], Step [1400/1875], d_loss: -0.1450, g_loss: -1.3235\n",
      "Epoch [33/300], Step [1600/1875], d_loss: -0.1205, g_loss: -2.0596\n",
      "Epoch [33/300], Step [1800/1875], d_loss: -0.0380, g_loss: -1.2782\n",
      "Epoch [34/300], Step [200/1875], d_loss: -0.1694, g_loss: -0.9761\n",
      "Epoch [34/300], Step [400/1875], d_loss: -0.1631, g_loss: -0.3423\n",
      "Epoch [34/300], Step [600/1875], d_loss: -0.1497, g_loss: -0.3879\n",
      "Epoch [34/300], Step [800/1875], d_loss: -0.2445, g_loss: 1.1896\n",
      "Epoch [34/300], Step [1000/1875], d_loss: -0.0674, g_loss: -2.0061\n",
      "Epoch [34/300], Step [1200/1875], d_loss: -0.2198, g_loss: -1.9924\n",
      "Epoch [34/300], Step [1400/1875], d_loss: 0.2858, g_loss: -1.2177\n",
      "Epoch [34/300], Step [1600/1875], d_loss: -0.0957, g_loss: -0.1831\n",
      "Epoch [34/300], Step [1800/1875], d_loss: -0.1586, g_loss: 1.5432\n",
      "Epoch [35/300], Step [200/1875], d_loss: -0.1381, g_loss: -0.2131\n",
      "Epoch [35/300], Step [400/1875], d_loss: -0.1368, g_loss: -0.3295\n",
      "Epoch [35/300], Step [600/1875], d_loss: -0.2764, g_loss: -1.5324\n",
      "Epoch [35/300], Step [800/1875], d_loss: -0.2227, g_loss: -2.2294\n",
      "Epoch [35/300], Step [1000/1875], d_loss: -0.2474, g_loss: -1.7302\n",
      "Epoch [35/300], Step [1200/1875], d_loss: -0.2236, g_loss: -1.8371\n",
      "Epoch [35/300], Step [1400/1875], d_loss: -0.1101, g_loss: -0.7763\n",
      "Epoch [35/300], Step [1600/1875], d_loss: -0.1712, g_loss: 0.2289\n",
      "Epoch [35/300], Step [1800/1875], d_loss: -0.1125, g_loss: -1.0110\n",
      "Epoch [36/300], Step [200/1875], d_loss: -0.1163, g_loss: 0.2785\n",
      "Epoch [36/300], Step [400/1875], d_loss: -0.0544, g_loss: -0.5371\n",
      "Epoch [36/300], Step [600/1875], d_loss: -0.1881, g_loss: -1.3293\n",
      "Epoch [36/300], Step [800/1875], d_loss: -0.3503, g_loss: -0.2750\n",
      "Epoch [36/300], Step [1000/1875], d_loss: -0.1842, g_loss: -1.9223\n",
      "Epoch [36/300], Step [1200/1875], d_loss: -0.1238, g_loss: -0.9189\n",
      "Epoch [36/300], Step [1400/1875], d_loss: -0.1518, g_loss: -2.1465\n",
      "Epoch [36/300], Step [1600/1875], d_loss: -0.1117, g_loss: -1.0168\n",
      "Epoch [36/300], Step [1800/1875], d_loss: -0.1947, g_loss: 0.2034\n",
      "Epoch [37/300], Step [200/1875], d_loss: -0.1297, g_loss: -0.4495\n",
      "Epoch [37/300], Step [400/1875], d_loss: -0.1653, g_loss: -1.2646\n",
      "Epoch [37/300], Step [600/1875], d_loss: -0.2698, g_loss: 1.1228\n",
      "Epoch [37/300], Step [800/1875], d_loss: -0.1987, g_loss: 1.6639\n",
      "Epoch [37/300], Step [1000/1875], d_loss: -0.2621, g_loss: -0.6243\n",
      "Epoch [37/300], Step [1200/1875], d_loss: -0.2769, g_loss: -2.3249\n",
      "Epoch [37/300], Step [1400/1875], d_loss: -0.2110, g_loss: -1.1120\n",
      "Epoch [37/300], Step [1600/1875], d_loss: -0.1498, g_loss: -0.3351\n",
      "Epoch [37/300], Step [1800/1875], d_loss: -0.1832, g_loss: -0.6590\n",
      "Epoch [38/300], Step [200/1875], d_loss: -0.1440, g_loss: -1.2623\n",
      "Epoch [38/300], Step [400/1875], d_loss: -0.3008, g_loss: -2.1312\n",
      "Epoch [38/300], Step [600/1875], d_loss: -0.3193, g_loss: -1.1001\n",
      "Epoch [38/300], Step [800/1875], d_loss: -0.0871, g_loss: -1.7802\n",
      "Epoch [38/300], Step [1000/1875], d_loss: -0.2397, g_loss: -0.3711\n",
      "Epoch [38/300], Step [1200/1875], d_loss: -0.2217, g_loss: 0.0637\n",
      "Epoch [38/300], Step [1400/1875], d_loss: -0.1486, g_loss: -2.6391\n",
      "Epoch [38/300], Step [1600/1875], d_loss: -0.1660, g_loss: -2.0048\n",
      "Epoch [38/300], Step [1800/1875], d_loss: -0.2407, g_loss: -0.5380\n",
      "Epoch [39/300], Step [200/1875], d_loss: -0.2582, g_loss: 0.3872\n",
      "Epoch [39/300], Step [400/1875], d_loss: -0.3634, g_loss: 1.7166\n",
      "Epoch [39/300], Step [600/1875], d_loss: -0.0974, g_loss: -0.1590\n",
      "Epoch [39/300], Step [800/1875], d_loss: -0.1324, g_loss: 0.1135\n",
      "Epoch [39/300], Step [1000/1875], d_loss: -0.0757, g_loss: -0.8461\n",
      "Epoch [39/300], Step [1200/1875], d_loss: -0.0970, g_loss: 0.6074\n",
      "Epoch [39/300], Step [1400/1875], d_loss: -0.1231, g_loss: 0.4177\n",
      "Epoch [39/300], Step [1600/1875], d_loss: -0.1545, g_loss: 0.5035\n",
      "Epoch [39/300], Step [1800/1875], d_loss: -0.1799, g_loss: -0.1251\n",
      "Epoch [40/300], Step [200/1875], d_loss: -0.1466, g_loss: 0.1653\n",
      "Epoch [40/300], Step [400/1875], d_loss: -0.1595, g_loss: -0.6291\n",
      "Epoch [40/300], Step [600/1875], d_loss: -0.1128, g_loss: -2.0355\n",
      "Epoch [40/300], Step [800/1875], d_loss: -0.1174, g_loss: -0.3882\n",
      "Epoch [40/300], Step [1000/1875], d_loss: -0.1619, g_loss: -0.8263\n",
      "Epoch [40/300], Step [1200/1875], d_loss: -0.2325, g_loss: -1.0948\n",
      "Epoch [40/300], Step [1400/1875], d_loss: -0.0941, g_loss: 0.3489\n",
      "Epoch [40/300], Step [1600/1875], d_loss: -0.2353, g_loss: -1.5711\n",
      "Epoch [40/300], Step [1800/1875], d_loss: -0.0331, g_loss: 0.0775\n",
      "Epoch [41/300], Step [200/1875], d_loss: -0.0577, g_loss: -0.0703\n",
      "Epoch [41/300], Step [400/1875], d_loss: -0.0665, g_loss: -0.9647\n",
      "Epoch [41/300], Step [600/1875], d_loss: -0.1751, g_loss: 1.6768\n",
      "Epoch [41/300], Step [800/1875], d_loss: -0.1253, g_loss: 0.7511\n",
      "Epoch [41/300], Step [1000/1875], d_loss: -0.1769, g_loss: 0.1908\n",
      "Epoch [41/300], Step [1200/1875], d_loss: -0.1592, g_loss: -2.1560\n",
      "Epoch [41/300], Step [1400/1875], d_loss: -0.3379, g_loss: 2.2625\n",
      "Epoch [41/300], Step [1600/1875], d_loss: -0.2458, g_loss: 0.9011\n",
      "Epoch [41/300], Step [1800/1875], d_loss: 0.0288, g_loss: -1.6747\n",
      "Epoch [42/300], Step [200/1875], d_loss: -0.1453, g_loss: -0.4770\n",
      "Epoch [42/300], Step [400/1875], d_loss: -0.1184, g_loss: -0.0080\n",
      "Epoch [42/300], Step [600/1875], d_loss: -0.2249, g_loss: -1.1840\n",
      "Epoch [42/300], Step [800/1875], d_loss: -0.1431, g_loss: -0.3662\n",
      "Epoch [42/300], Step [1000/1875], d_loss: -0.0131, g_loss: -0.2507\n",
      "Epoch [42/300], Step [1200/1875], d_loss: -0.1706, g_loss: 0.9845\n",
      "Epoch [42/300], Step [1400/1875], d_loss: -0.2282, g_loss: 0.3652\n",
      "Epoch [42/300], Step [1600/1875], d_loss: -0.0940, g_loss: -1.2881\n",
      "Epoch [42/300], Step [1800/1875], d_loss: -0.1752, g_loss: -1.3366\n",
      "Epoch [43/300], Step [200/1875], d_loss: -0.1401, g_loss: 0.1568\n",
      "Epoch [43/300], Step [400/1875], d_loss: -0.0032, g_loss: -0.6179\n",
      "Epoch [43/300], Step [600/1875], d_loss: -0.0123, g_loss: -1.0142\n",
      "Epoch [43/300], Step [800/1875], d_loss: -0.1116, g_loss: -0.8885\n",
      "Epoch [43/300], Step [1000/1875], d_loss: -0.1748, g_loss: -0.1359\n",
      "Epoch [43/300], Step [1200/1875], d_loss: 0.0016, g_loss: -2.5691\n",
      "Epoch [43/300], Step [1400/1875], d_loss: -0.2832, g_loss: 0.8822\n",
      "Epoch [43/300], Step [1600/1875], d_loss: -0.2091, g_loss: 0.2444\n",
      "Epoch [43/300], Step [1800/1875], d_loss: 0.0679, g_loss: -0.4441\n",
      "Epoch [44/300], Step [200/1875], d_loss: -0.1854, g_loss: -0.3198\n",
      "Epoch [44/300], Step [400/1875], d_loss: -0.2001, g_loss: 0.2638\n",
      "Epoch [44/300], Step [600/1875], d_loss: -0.2588, g_loss: -0.8255\n",
      "Epoch [44/300], Step [800/1875], d_loss: -0.0648, g_loss: 0.3964\n",
      "Epoch [44/300], Step [1000/1875], d_loss: -0.1401, g_loss: -1.6241\n",
      "Epoch [44/300], Step [1200/1875], d_loss: -0.1732, g_loss: -1.2936\n",
      "Epoch [44/300], Step [1400/1875], d_loss: -0.1939, g_loss: -3.6042\n",
      "Epoch [44/300], Step [1600/1875], d_loss: -0.3207, g_loss: 0.4036\n",
      "Epoch [44/300], Step [1800/1875], d_loss: -0.2044, g_loss: 0.6605\n",
      "Epoch [45/300], Step [200/1875], d_loss: -0.1979, g_loss: -1.9737\n",
      "Epoch [45/300], Step [400/1875], d_loss: -0.1643, g_loss: -1.5888\n",
      "Epoch [45/300], Step [600/1875], d_loss: -0.2393, g_loss: -1.7426\n",
      "Epoch [45/300], Step [800/1875], d_loss: 0.0090, g_loss: -1.8268\n",
      "Epoch [45/300], Step [1000/1875], d_loss: -0.1880, g_loss: -1.3482\n",
      "Epoch [45/300], Step [1200/1875], d_loss: -0.0708, g_loss: 0.4402\n",
      "Epoch [45/300], Step [1400/1875], d_loss: -0.1664, g_loss: -0.7808\n",
      "Epoch [45/300], Step [1600/1875], d_loss: -0.1669, g_loss: -0.2948\n",
      "Epoch [45/300], Step [1800/1875], d_loss: -0.1536, g_loss: -1.5141\n",
      "Epoch [46/300], Step [200/1875], d_loss: -0.0879, g_loss: -0.9433\n",
      "Epoch [46/300], Step [400/1875], d_loss: -0.2910, g_loss: -1.9673\n",
      "Epoch [46/300], Step [600/1875], d_loss: -0.1632, g_loss: 0.2541\n",
      "Epoch [46/300], Step [800/1875], d_loss: -0.1455, g_loss: -0.8025\n",
      "Epoch [46/300], Step [1000/1875], d_loss: -0.1327, g_loss: -0.7522\n",
      "Epoch [46/300], Step [1200/1875], d_loss: -0.2008, g_loss: -1.0611\n",
      "Epoch [46/300], Step [1400/1875], d_loss: -0.0642, g_loss: -1.8807\n",
      "Epoch [46/300], Step [1600/1875], d_loss: -0.1437, g_loss: 0.0929\n",
      "Epoch [46/300], Step [1800/1875], d_loss: 0.0760, g_loss: -0.0535\n",
      "Epoch [47/300], Step [200/1875], d_loss: -0.2364, g_loss: -1.0866\n",
      "Epoch [47/300], Step [400/1875], d_loss: 0.3519, g_loss: -0.8568\n",
      "Epoch [47/300], Step [600/1875], d_loss: -0.1828, g_loss: 1.0645\n",
      "Epoch [47/300], Step [800/1875], d_loss: -0.3103, g_loss: -2.1788\n",
      "Epoch [47/300], Step [1000/1875], d_loss: 0.1719, g_loss: -0.4941\n",
      "Epoch [47/300], Step [1200/1875], d_loss: -0.1973, g_loss: -0.0716\n",
      "Epoch [47/300], Step [1400/1875], d_loss: -0.1464, g_loss: -0.0677\n",
      "Epoch [47/300], Step [1600/1875], d_loss: -0.2495, g_loss: -2.2605\n",
      "Epoch [47/300], Step [1800/1875], d_loss: -0.1571, g_loss: -0.0950\n",
      "Epoch [48/300], Step [200/1875], d_loss: -0.0608, g_loss: -0.1077\n",
      "Epoch [48/300], Step [400/1875], d_loss: -0.2886, g_loss: -0.7005\n",
      "Epoch [48/300], Step [600/1875], d_loss: -0.1096, g_loss: 0.2078\n",
      "Epoch [48/300], Step [800/1875], d_loss: -0.1061, g_loss: -1.1585\n",
      "Epoch [48/300], Step [1000/1875], d_loss: -0.1695, g_loss: 1.0567\n",
      "Epoch [48/300], Step [1200/1875], d_loss: -0.0746, g_loss: -1.9582\n",
      "Epoch [48/300], Step [1400/1875], d_loss: -0.1295, g_loss: -1.3840\n",
      "Epoch [48/300], Step [1600/1875], d_loss: -0.1499, g_loss: 0.6521\n",
      "Epoch [48/300], Step [1800/1875], d_loss: -0.2091, g_loss: -0.5666\n",
      "Epoch [49/300], Step [200/1875], d_loss: -0.1574, g_loss: -0.9265\n",
      "Epoch [49/300], Step [400/1875], d_loss: -0.2259, g_loss: 2.8684\n",
      "Epoch [49/300], Step [600/1875], d_loss: -0.1642, g_loss: -1.2351\n",
      "Epoch [49/300], Step [800/1875], d_loss: -0.0037, g_loss: -1.6298\n",
      "Epoch [49/300], Step [1000/1875], d_loss: -0.0533, g_loss: 0.4296\n",
      "Epoch [49/300], Step [1200/1875], d_loss: -0.1352, g_loss: -0.9246\n",
      "Epoch [49/300], Step [1400/1875], d_loss: -0.2073, g_loss: -0.2542\n",
      "Epoch [49/300], Step [1600/1875], d_loss: -0.0091, g_loss: -1.5192\n",
      "Epoch [49/300], Step [1800/1875], d_loss: -0.2338, g_loss: -0.2626\n",
      "Epoch [50/300], Step [200/1875], d_loss: -0.3070, g_loss: 1.4282\n",
      "Epoch [50/300], Step [400/1875], d_loss: -0.0665, g_loss: -2.4415\n",
      "Epoch [50/300], Step [600/1875], d_loss: -0.1181, g_loss: -0.3136\n",
      "Epoch [50/300], Step [800/1875], d_loss: -0.2388, g_loss: -1.8928\n",
      "Epoch [50/300], Step [1000/1875], d_loss: -0.1779, g_loss: -1.4995\n",
      "Epoch [50/300], Step [1200/1875], d_loss: -0.1317, g_loss: -1.4821\n",
      "Epoch [50/300], Step [1400/1875], d_loss: -0.2190, g_loss: -0.7750\n",
      "Epoch [50/300], Step [1600/1875], d_loss: 0.1529, g_loss: -1.3344\n",
      "Epoch [50/300], Step [1800/1875], d_loss: -0.1410, g_loss: -0.9828\n",
      "Epoch [51/300], Step [200/1875], d_loss: -0.1550, g_loss: -1.7507\n",
      "Epoch [51/300], Step [400/1875], d_loss: -0.0833, g_loss: 0.6313\n",
      "Epoch [51/300], Step [600/1875], d_loss: -0.0257, g_loss: -0.3235\n",
      "Epoch [51/300], Step [800/1875], d_loss: -0.1473, g_loss: -1.1025\n",
      "Epoch [51/300], Step [1000/1875], d_loss: -0.1085, g_loss: -0.8471\n",
      "Epoch [51/300], Step [1200/1875], d_loss: -0.0575, g_loss: -0.3795\n",
      "Epoch [51/300], Step [1400/1875], d_loss: -0.1708, g_loss: 0.7527\n",
      "Epoch [51/300], Step [1600/1875], d_loss: -0.1755, g_loss: -1.4108\n",
      "Epoch [51/300], Step [1800/1875], d_loss: -0.0301, g_loss: -0.3629\n",
      "Epoch [52/300], Step [200/1875], d_loss: -0.1929, g_loss: 0.7880\n",
      "Epoch [52/300], Step [400/1875], d_loss: -0.1484, g_loss: -0.6408\n",
      "Epoch [52/300], Step [600/1875], d_loss: -0.1430, g_loss: -0.2269\n",
      "Epoch [52/300], Step [800/1875], d_loss: -0.1120, g_loss: -1.6288\n",
      "Epoch [52/300], Step [1000/1875], d_loss: -0.2226, g_loss: 0.4213\n",
      "Epoch [52/300], Step [1200/1875], d_loss: -0.1620, g_loss: -1.7209\n",
      "Epoch [52/300], Step [1400/1875], d_loss: -0.1016, g_loss: -0.2988\n",
      "Epoch [52/300], Step [1600/1875], d_loss: -0.2247, g_loss: -1.4666\n",
      "Epoch [52/300], Step [1800/1875], d_loss: -0.1454, g_loss: 0.4861\n",
      "Epoch [53/300], Step [200/1875], d_loss: -0.1239, g_loss: -0.2143\n",
      "Epoch [53/300], Step [400/1875], d_loss: -0.0750, g_loss: -1.1508\n",
      "Epoch [53/300], Step [600/1875], d_loss: -0.1054, g_loss: -1.0378\n",
      "Epoch [53/300], Step [800/1875], d_loss: -0.1584, g_loss: -1.8267\n",
      "Epoch [53/300], Step [1000/1875], d_loss: -0.1173, g_loss: -2.1605\n",
      "Epoch [53/300], Step [1200/1875], d_loss: -0.0520, g_loss: -0.8271\n",
      "Epoch [53/300], Step [1400/1875], d_loss: -0.1946, g_loss: 0.4505\n",
      "Epoch [53/300], Step [1600/1875], d_loss: -0.0086, g_loss: -1.1081\n",
      "Epoch [53/300], Step [1800/1875], d_loss: -0.0386, g_loss: -0.0927\n",
      "Epoch [54/300], Step [200/1875], d_loss: -0.1363, g_loss: -1.9433\n",
      "Epoch [54/300], Step [400/1875], d_loss: -0.0998, g_loss: 0.1014\n",
      "Epoch [54/300], Step [600/1875], d_loss: -0.1597, g_loss: -0.3936\n",
      "Epoch [54/300], Step [800/1875], d_loss: -0.1557, g_loss: 0.4505\n",
      "Epoch [54/300], Step [1000/1875], d_loss: -0.1890, g_loss: -1.7552\n",
      "Epoch [54/300], Step [1200/1875], d_loss: -0.1367, g_loss: 0.5024\n",
      "Epoch [54/300], Step [1400/1875], d_loss: -0.2716, g_loss: -1.6239\n",
      "Epoch [54/300], Step [1600/1875], d_loss: 0.0496, g_loss: -0.2162\n",
      "Epoch [54/300], Step [1800/1875], d_loss: -0.2871, g_loss: -2.4268\n",
      "Epoch [55/300], Step [200/1875], d_loss: -0.0591, g_loss: -0.5382\n",
      "Epoch [55/300], Step [400/1875], d_loss: -0.0650, g_loss: 0.1591\n",
      "Epoch [55/300], Step [600/1875], d_loss: -0.1740, g_loss: -0.6725\n",
      "Epoch [55/300], Step [800/1875], d_loss: -0.1847, g_loss: -2.5744\n",
      "Epoch [55/300], Step [1000/1875], d_loss: -0.1290, g_loss: -0.5892\n",
      "Epoch [55/300], Step [1200/1875], d_loss: -0.1272, g_loss: -1.9777\n",
      "Epoch [55/300], Step [1400/1875], d_loss: -0.0444, g_loss: -1.4484\n",
      "Epoch [55/300], Step [1600/1875], d_loss: -0.0731, g_loss: -0.2621\n",
      "Epoch [55/300], Step [1800/1875], d_loss: -0.0847, g_loss: -0.9696\n",
      "Epoch [56/300], Step [200/1875], d_loss: -0.1113, g_loss: -0.4009\n",
      "Epoch [56/300], Step [400/1875], d_loss: 0.0187, g_loss: 0.0902\n",
      "Epoch [56/300], Step [600/1875], d_loss: -0.1534, g_loss: 0.2735\n",
      "Epoch [56/300], Step [800/1875], d_loss: -0.0848, g_loss: -1.7475\n",
      "Epoch [56/300], Step [1000/1875], d_loss: 0.0269, g_loss: -0.6668\n",
      "Epoch [56/300], Step [1200/1875], d_loss: -0.1050, g_loss: 0.4633\n",
      "Epoch [56/300], Step [1400/1875], d_loss: -0.1072, g_loss: -0.7086\n",
      "Epoch [56/300], Step [1600/1875], d_loss: -0.0820, g_loss: -0.6178\n",
      "Epoch [56/300], Step [1800/1875], d_loss: -0.1811, g_loss: -0.6274\n",
      "Epoch [57/300], Step [200/1875], d_loss: -0.1158, g_loss: -0.6711\n",
      "Epoch [57/300], Step [400/1875], d_loss: -0.2188, g_loss: 0.4857\n",
      "Epoch [57/300], Step [600/1875], d_loss: -0.0428, g_loss: 0.2248\n",
      "Epoch [57/300], Step [800/1875], d_loss: -0.1250, g_loss: -1.6846\n",
      "Epoch [57/300], Step [1000/1875], d_loss: -0.1343, g_loss: -2.1033\n",
      "Epoch [57/300], Step [1200/1875], d_loss: -0.0618, g_loss: -1.8186\n",
      "Epoch [57/300], Step [1400/1875], d_loss: -0.1247, g_loss: 0.3230\n",
      "Epoch [57/300], Step [1600/1875], d_loss: -0.1498, g_loss: -1.1063\n",
      "Epoch [57/300], Step [1800/1875], d_loss: -0.1416, g_loss: -0.5637\n",
      "Epoch [58/300], Step [200/1875], d_loss: 0.0106, g_loss: -0.1301\n",
      "Epoch [58/300], Step [400/1875], d_loss: 0.0158, g_loss: 0.7724\n",
      "Epoch [58/300], Step [600/1875], d_loss: 0.0549, g_loss: -0.5111\n",
      "Epoch [58/300], Step [800/1875], d_loss: -0.0664, g_loss: -1.7059\n",
      "Epoch [58/300], Step [1000/1875], d_loss: -0.1479, g_loss: -0.0577\n",
      "Epoch [58/300], Step [1200/1875], d_loss: -0.1743, g_loss: -1.0156\n",
      "Epoch [58/300], Step [1400/1875], d_loss: -0.1790, g_loss: -1.3673\n",
      "Epoch [58/300], Step [1600/1875], d_loss: -0.0514, g_loss: -0.0554\n",
      "Epoch [58/300], Step [1800/1875], d_loss: -0.1461, g_loss: -1.0516\n",
      "Epoch [59/300], Step [200/1875], d_loss: -0.1643, g_loss: -1.7620\n",
      "Epoch [59/300], Step [400/1875], d_loss: -0.1902, g_loss: -1.6360\n",
      "Epoch [59/300], Step [600/1875], d_loss: -0.2419, g_loss: -0.7795\n",
      "Epoch [59/300], Step [800/1875], d_loss: -0.2485, g_loss: 1.7915\n",
      "Epoch [59/300], Step [1000/1875], d_loss: -0.0817, g_loss: -2.4528\n",
      "Epoch [59/300], Step [1200/1875], d_loss: -0.1718, g_loss: -1.7466\n",
      "Epoch [59/300], Step [1400/1875], d_loss: -0.1269, g_loss: -1.1787\n",
      "Epoch [59/300], Step [1600/1875], d_loss: -0.1811, g_loss: -2.0964\n",
      "Epoch [59/300], Step [1800/1875], d_loss: -0.2221, g_loss: -0.6564\n",
      "Epoch [60/300], Step [200/1875], d_loss: -0.2714, g_loss: -1.9650\n",
      "Epoch [60/300], Step [400/1875], d_loss: -0.0882, g_loss: -0.7890\n",
      "Epoch [60/300], Step [600/1875], d_loss: -0.2079, g_loss: 0.7418\n",
      "Epoch [60/300], Step [800/1875], d_loss: -0.1207, g_loss: -0.1618\n",
      "Epoch [60/300], Step [1000/1875], d_loss: 0.0048, g_loss: -0.6341\n",
      "Epoch [60/300], Step [1200/1875], d_loss: -0.1117, g_loss: -0.7832\n",
      "Epoch [60/300], Step [1400/1875], d_loss: -0.1211, g_loss: -0.3361\n",
      "Epoch [60/300], Step [1600/1875], d_loss: -0.2639, g_loss: -2.1111\n",
      "Epoch [60/300], Step [1800/1875], d_loss: -0.1898, g_loss: -0.2398\n",
      "Epoch [61/300], Step [200/1875], d_loss: -0.1056, g_loss: -0.6056\n",
      "Epoch [61/300], Step [400/1875], d_loss: -0.0668, g_loss: 0.5121\n",
      "Epoch [61/300], Step [600/1875], d_loss: -0.1122, g_loss: -0.4242\n",
      "Epoch [61/300], Step [800/1875], d_loss: -0.1260, g_loss: 1.6021\n",
      "Epoch [61/300], Step [1000/1875], d_loss: -0.0627, g_loss: -0.2990\n",
      "Epoch [61/300], Step [1200/1875], d_loss: -0.1107, g_loss: -1.2247\n",
      "Epoch [61/300], Step [1400/1875], d_loss: -0.1590, g_loss: -0.2316\n",
      "Epoch [61/300], Step [1600/1875], d_loss: -0.1733, g_loss: -2.6294\n",
      "Epoch [61/300], Step [1800/1875], d_loss: -0.1459, g_loss: 0.7581\n",
      "Epoch [62/300], Step [200/1875], d_loss: -0.0685, g_loss: -0.2092\n",
      "Epoch [62/300], Step [400/1875], d_loss: -0.2356, g_loss: -2.4419\n",
      "Epoch [62/300], Step [600/1875], d_loss: -0.0497, g_loss: -1.1372\n",
      "Epoch [62/300], Step [800/1875], d_loss: -0.1287, g_loss: -0.1928\n",
      "Epoch [62/300], Step [1000/1875], d_loss: -0.2284, g_loss: 0.4644\n",
      "Epoch [62/300], Step [1200/1875], d_loss: -0.2146, g_loss: -2.5376\n",
      "Epoch [62/300], Step [1400/1875], d_loss: -0.1168, g_loss: 0.3722\n",
      "Epoch [62/300], Step [1600/1875], d_loss: -0.1847, g_loss: 1.4057\n",
      "Epoch [62/300], Step [1800/1875], d_loss: -0.0645, g_loss: 0.0306\n",
      "Epoch [63/300], Step [200/1875], d_loss: -0.1855, g_loss: -1.2146\n",
      "Epoch [63/300], Step [400/1875], d_loss: -0.2102, g_loss: 0.1453\n",
      "Epoch [63/300], Step [600/1875], d_loss: -0.0692, g_loss: -0.5969\n",
      "Epoch [63/300], Step [800/1875], d_loss: -0.2175, g_loss: 0.3958\n",
      "Epoch [63/300], Step [1000/1875], d_loss: -0.0639, g_loss: -0.7711\n",
      "Epoch [63/300], Step [1200/1875], d_loss: -0.2179, g_loss: 0.3039\n",
      "Epoch [63/300], Step [1400/1875], d_loss: -0.1197, g_loss: -1.0459\n",
      "Epoch [63/300], Step [1600/1875], d_loss: -0.3581, g_loss: -1.5422\n",
      "Epoch [63/300], Step [1800/1875], d_loss: -0.2223, g_loss: -0.8474\n",
      "Epoch [64/300], Step [200/1875], d_loss: -0.1272, g_loss: 0.2945\n",
      "Epoch [64/300], Step [400/1875], d_loss: -0.0711, g_loss: -0.0244\n",
      "Epoch [64/300], Step [600/1875], d_loss: -0.0989, g_loss: 0.0225\n",
      "Epoch [64/300], Step [800/1875], d_loss: -0.1171, g_loss: -1.0804\n",
      "Epoch [64/300], Step [1000/1875], d_loss: -0.0673, g_loss: -0.8900\n",
      "Epoch [64/300], Step [1200/1875], d_loss: -0.1078, g_loss: -0.2069\n",
      "Epoch [64/300], Step [1400/1875], d_loss: -0.0715, g_loss: -0.1541\n",
      "Epoch [64/300], Step [1600/1875], d_loss: -0.1058, g_loss: -1.0985\n",
      "Epoch [64/300], Step [1800/1875], d_loss: -0.1410, g_loss: -0.2297\n",
      "Epoch [65/300], Step [200/1875], d_loss: -0.0899, g_loss: 0.7044\n",
      "Epoch [65/300], Step [400/1875], d_loss: -0.2185, g_loss: 0.1379\n",
      "Epoch [65/300], Step [600/1875], d_loss: -0.1571, g_loss: -1.4557\n",
      "Epoch [65/300], Step [800/1875], d_loss: -0.0476, g_loss: 0.2478\n",
      "Epoch [65/300], Step [1000/1875], d_loss: -0.2026, g_loss: -1.7211\n",
      "Epoch [65/300], Step [1200/1875], d_loss: -0.1949, g_loss: -3.2020\n",
      "Epoch [65/300], Step [1400/1875], d_loss: -0.0668, g_loss: -1.7931\n",
      "Epoch [65/300], Step [1600/1875], d_loss: -0.0752, g_loss: -1.7048\n",
      "Epoch [65/300], Step [1800/1875], d_loss: -0.0550, g_loss: -0.9797\n",
      "Epoch [66/300], Step [200/1875], d_loss: -0.1469, g_loss: -1.9438\n",
      "Epoch [66/300], Step [400/1875], d_loss: -0.1024, g_loss: -0.8549\n",
      "Epoch [66/300], Step [600/1875], d_loss: -0.1310, g_loss: -0.0485\n",
      "Epoch [66/300], Step [800/1875], d_loss: -0.0007, g_loss: -1.2324\n",
      "Epoch [66/300], Step [1000/1875], d_loss: -0.0796, g_loss: -0.7592\n",
      "Epoch [66/300], Step [1200/1875], d_loss: -0.0701, g_loss: -1.6265\n",
      "Epoch [66/300], Step [1400/1875], d_loss: -0.2371, g_loss: -1.7615\n",
      "Epoch [66/300], Step [1600/1875], d_loss: -0.0675, g_loss: -2.0611\n",
      "Epoch [66/300], Step [1800/1875], d_loss: -0.1134, g_loss: -1.3137\n",
      "Epoch [67/300], Step [200/1875], d_loss: -0.0721, g_loss: -0.5919\n",
      "Epoch [67/300], Step [400/1875], d_loss: -0.0895, g_loss: -1.4186\n",
      "Epoch [67/300], Step [600/1875], d_loss: -0.2517, g_loss: -1.3174\n",
      "Epoch [67/300], Step [800/1875], d_loss: -0.1001, g_loss: -1.1710\n",
      "Epoch [67/300], Step [1000/1875], d_loss: 0.1112, g_loss: -0.0984\n",
      "Epoch [67/300], Step [1200/1875], d_loss: -0.1286, g_loss: -0.9959\n",
      "Epoch [67/300], Step [1400/1875], d_loss: -0.0252, g_loss: -1.2314\n",
      "Epoch [67/300], Step [1600/1875], d_loss: -0.1464, g_loss: -1.1904\n",
      "Epoch [67/300], Step [1800/1875], d_loss: -0.1517, g_loss: -1.4567\n",
      "Epoch [68/300], Step [200/1875], d_loss: -0.2409, g_loss: -0.4548\n",
      "Epoch [68/300], Step [400/1875], d_loss: -0.2232, g_loss: 1.3567\n",
      "Epoch [68/300], Step [600/1875], d_loss: -0.0098, g_loss: 0.0623\n",
      "Epoch [68/300], Step [800/1875], d_loss: -0.0643, g_loss: -0.7823\n",
      "Epoch [68/300], Step [1000/1875], d_loss: -0.1769, g_loss: 0.1471\n",
      "Epoch [68/300], Step [1200/1875], d_loss: -0.2018, g_loss: 0.5955\n",
      "Epoch [68/300], Step [1400/1875], d_loss: -0.1191, g_loss: -2.1034\n",
      "Epoch [68/300], Step [1600/1875], d_loss: -0.1954, g_loss: -0.4007\n",
      "Epoch [68/300], Step [1800/1875], d_loss: -0.0618, g_loss: 0.0020\n",
      "Epoch [69/300], Step [200/1875], d_loss: -0.0678, g_loss: -2.4193\n",
      "Epoch [69/300], Step [400/1875], d_loss: -0.1047, g_loss: -0.0331\n",
      "Epoch [69/300], Step [600/1875], d_loss: -0.3254, g_loss: -2.6421\n",
      "Epoch [69/300], Step [800/1875], d_loss: -0.2265, g_loss: -1.5270\n",
      "Epoch [69/300], Step [1000/1875], d_loss: -0.1022, g_loss: -0.4053\n",
      "Epoch [69/300], Step [1200/1875], d_loss: -0.1220, g_loss: 0.3853\n",
      "Epoch [69/300], Step [1400/1875], d_loss: -0.1039, g_loss: -1.5249\n",
      "Epoch [69/300], Step [1600/1875], d_loss: -0.0604, g_loss: -1.2408\n",
      "Epoch [69/300], Step [1800/1875], d_loss: -0.1265, g_loss: -1.5181\n",
      "Epoch [70/300], Step [200/1875], d_loss: -0.1229, g_loss: 0.5711\n",
      "Epoch [70/300], Step [400/1875], d_loss: -0.1121, g_loss: 0.1005\n",
      "Epoch [70/300], Step [600/1875], d_loss: -0.1161, g_loss: -0.4440\n",
      "Epoch [70/300], Step [800/1875], d_loss: -0.1104, g_loss: -0.1051\n",
      "Epoch [70/300], Step [1000/1875], d_loss: -0.0830, g_loss: 0.2416\n",
      "Epoch [70/300], Step [1200/1875], d_loss: -0.1983, g_loss: -1.4044\n",
      "Epoch [70/300], Step [1400/1875], d_loss: -0.1170, g_loss: -1.8089\n",
      "Epoch [70/300], Step [1600/1875], d_loss: -0.1355, g_loss: -0.8215\n",
      "Epoch [70/300], Step [1800/1875], d_loss: -0.1073, g_loss: -1.5080\n",
      "Epoch [71/300], Step [200/1875], d_loss: -0.0465, g_loss: 0.1230\n",
      "Epoch [71/300], Step [400/1875], d_loss: -0.2657, g_loss: -1.0689\n",
      "Epoch [71/300], Step [600/1875], d_loss: -0.0942, g_loss: -0.6129\n",
      "Epoch [71/300], Step [800/1875], d_loss: -0.1259, g_loss: -0.0026\n",
      "Epoch [71/300], Step [1000/1875], d_loss: -0.0906, g_loss: -0.7439\n",
      "Epoch [71/300], Step [1200/1875], d_loss: 0.1256, g_loss: -0.9700\n",
      "Epoch [71/300], Step [1400/1875], d_loss: -0.1341, g_loss: -1.1142\n",
      "Epoch [71/300], Step [1600/1875], d_loss: -0.1667, g_loss: -0.8982\n",
      "Epoch [71/300], Step [1800/1875], d_loss: -0.1037, g_loss: -1.3997\n",
      "Epoch [72/300], Step [200/1875], d_loss: -0.1483, g_loss: -0.6815\n",
      "Epoch [72/300], Step [400/1875], d_loss: 0.0246, g_loss: -0.8830\n",
      "Epoch [72/300], Step [600/1875], d_loss: -0.1283, g_loss: 0.3674\n",
      "Epoch [72/300], Step [800/1875], d_loss: -0.0737, g_loss: -0.1763\n",
      "Epoch [72/300], Step [1000/1875], d_loss: 0.0292, g_loss: -1.9152\n",
      "Epoch [72/300], Step [1200/1875], d_loss: -0.1424, g_loss: -0.0869\n",
      "Epoch [72/300], Step [1400/1875], d_loss: -0.1263, g_loss: -0.8174\n",
      "Epoch [72/300], Step [1600/1875], d_loss: -0.0264, g_loss: -0.3791\n",
      "Epoch [72/300], Step [1800/1875], d_loss: 0.0106, g_loss: -1.5026\n",
      "Epoch [73/300], Step [200/1875], d_loss: -0.0497, g_loss: 1.0187\n",
      "Epoch [73/300], Step [400/1875], d_loss: -0.0910, g_loss: 1.3270\n",
      "Epoch [73/300], Step [600/1875], d_loss: -0.1414, g_loss: 0.5622\n",
      "Epoch [73/300], Step [800/1875], d_loss: -0.1646, g_loss: -0.6375\n",
      "Epoch [73/300], Step [1000/1875], d_loss: -0.1489, g_loss: -0.7989\n",
      "Epoch [73/300], Step [1200/1875], d_loss: -0.1785, g_loss: -1.3993\n",
      "Epoch [73/300], Step [1400/1875], d_loss: -0.1883, g_loss: 0.3231\n",
      "Epoch [73/300], Step [1600/1875], d_loss: -0.0711, g_loss: -0.8947\n",
      "Epoch [73/300], Step [1800/1875], d_loss: -0.2342, g_loss: 1.1944\n",
      "Epoch [74/300], Step [200/1875], d_loss: -0.1066, g_loss: -1.3175\n",
      "Epoch [74/300], Step [400/1875], d_loss: -0.0794, g_loss: -0.4989\n",
      "Epoch [74/300], Step [600/1875], d_loss: -0.1343, g_loss: 0.1754\n",
      "Epoch [74/300], Step [800/1875], d_loss: -0.0350, g_loss: -0.3266\n",
      "Epoch [74/300], Step [1000/1875], d_loss: -0.0154, g_loss: -1.1408\n",
      "Epoch [74/300], Step [1200/1875], d_loss: -0.1221, g_loss: 0.7893\n",
      "Epoch [74/300], Step [1400/1875], d_loss: -0.2250, g_loss: 0.7434\n",
      "Epoch [74/300], Step [1600/1875], d_loss: -0.2025, g_loss: -1.9854\n",
      "Epoch [74/300], Step [1800/1875], d_loss: -0.2644, g_loss: -2.2452\n",
      "Epoch [75/300], Step [200/1875], d_loss: -0.0053, g_loss: -0.7637\n",
      "Epoch [75/300], Step [400/1875], d_loss: -0.1409, g_loss: -1.1957\n",
      "Epoch [75/300], Step [600/1875], d_loss: -0.1020, g_loss: -0.6266\n",
      "Epoch [75/300], Step [800/1875], d_loss: -0.0864, g_loss: -0.0601\n",
      "Epoch [75/300], Step [1000/1875], d_loss: -0.0653, g_loss: 0.0288\n",
      "Epoch [75/300], Step [1200/1875], d_loss: -0.1686, g_loss: -1.4917\n",
      "Epoch [75/300], Step [1400/1875], d_loss: -0.1401, g_loss: -0.7307\n",
      "Epoch [75/300], Step [1600/1875], d_loss: -0.1665, g_loss: 0.2065\n",
      "Epoch [75/300], Step [1800/1875], d_loss: -0.1669, g_loss: -1.4678\n",
      "Epoch [76/300], Step [200/1875], d_loss: -0.1540, g_loss: -0.2127\n",
      "Epoch [76/300], Step [400/1875], d_loss: -0.1970, g_loss: -1.8021\n",
      "Epoch [76/300], Step [600/1875], d_loss: -0.1722, g_loss: -1.1834\n",
      "Epoch [76/300], Step [800/1875], d_loss: -0.0609, g_loss: -1.4332\n",
      "Epoch [76/300], Step [1000/1875], d_loss: -0.1848, g_loss: -0.3824\n",
      "Epoch [76/300], Step [1200/1875], d_loss: -0.1647, g_loss: -1.8647\n",
      "Epoch [76/300], Step [1400/1875], d_loss: -0.1802, g_loss: -1.6228\n",
      "Epoch [76/300], Step [1600/1875], d_loss: -0.0337, g_loss: -0.1750\n",
      "Epoch [76/300], Step [1800/1875], d_loss: -0.1305, g_loss: -0.2588\n",
      "Epoch [77/300], Step [200/1875], d_loss: -0.0376, g_loss: -1.6263\n",
      "Epoch [77/300], Step [400/1875], d_loss: -0.1513, g_loss: -2.4127\n",
      "Epoch [77/300], Step [600/1875], d_loss: -0.0483, g_loss: -1.1071\n",
      "Epoch [77/300], Step [800/1875], d_loss: 0.0652, g_loss: -0.7861\n",
      "Epoch [77/300], Step [1000/1875], d_loss: -0.0451, g_loss: -1.0061\n",
      "Epoch [77/300], Step [1200/1875], d_loss: -0.1373, g_loss: 0.4320\n",
      "Epoch [77/300], Step [1400/1875], d_loss: -0.0938, g_loss: -0.7899\n",
      "Epoch [77/300], Step [1600/1875], d_loss: -0.1390, g_loss: -0.5322\n",
      "Epoch [77/300], Step [1800/1875], d_loss: -0.1374, g_loss: -0.1283\n",
      "Epoch [78/300], Step [200/1875], d_loss: -0.1068, g_loss: 0.5849\n",
      "Epoch [78/300], Step [400/1875], d_loss: -0.0294, g_loss: -1.5839\n",
      "Epoch [78/300], Step [600/1875], d_loss: -0.0864, g_loss: 0.2874\n",
      "Epoch [78/300], Step [800/1875], d_loss: -0.1400, g_loss: -1.0835\n",
      "Epoch [78/300], Step [1000/1875], d_loss: -0.1344, g_loss: -1.5256\n",
      "Epoch [78/300], Step [1200/1875], d_loss: -0.1089, g_loss: -1.3455\n",
      "Epoch [78/300], Step [1400/1875], d_loss: -0.1105, g_loss: -0.4650\n",
      "Epoch [78/300], Step [1600/1875], d_loss: -0.0631, g_loss: -0.3949\n",
      "Epoch [78/300], Step [1800/1875], d_loss: -0.0062, g_loss: -0.6380\n",
      "Epoch [79/300], Step [200/1875], d_loss: -0.1304, g_loss: -1.2763\n",
      "Epoch [79/300], Step [400/1875], d_loss: -0.1839, g_loss: -0.0879\n",
      "Epoch [79/300], Step [600/1875], d_loss: -0.0390, g_loss: -1.2393\n",
      "Epoch [79/300], Step [800/1875], d_loss: -0.1515, g_loss: -1.1097\n",
      "Epoch [79/300], Step [1000/1875], d_loss: -0.1788, g_loss: 0.5769\n",
      "Epoch [79/300], Step [1200/1875], d_loss: -0.0922, g_loss: -0.8441\n",
      "Epoch [79/300], Step [1400/1875], d_loss: -0.1435, g_loss: -2.0285\n",
      "Epoch [79/300], Step [1600/1875], d_loss: -0.0412, g_loss: -0.4346\n",
      "Epoch [79/300], Step [1800/1875], d_loss: -0.0709, g_loss: -1.9363\n",
      "Epoch [80/300], Step [200/1875], d_loss: -0.0246, g_loss: 0.3845\n",
      "Epoch [80/300], Step [400/1875], d_loss: -0.1281, g_loss: -1.4842\n",
      "Epoch [80/300], Step [600/1875], d_loss: 0.0415, g_loss: -1.3733\n",
      "Epoch [80/300], Step [800/1875], d_loss: -0.0324, g_loss: -0.4596\n",
      "Epoch [80/300], Step [1000/1875], d_loss: -0.0328, g_loss: 0.1246\n",
      "Epoch [80/300], Step [1200/1875], d_loss: -0.1669, g_loss: -2.4270\n",
      "Epoch [80/300], Step [1400/1875], d_loss: -0.0776, g_loss: -1.9139\n",
      "Epoch [80/300], Step [1600/1875], d_loss: -0.1517, g_loss: -2.2231\n",
      "Epoch [80/300], Step [1800/1875], d_loss: 0.0130, g_loss: -0.9904\n",
      "Epoch [81/300], Step [200/1875], d_loss: -0.0994, g_loss: -0.8639\n",
      "Epoch [81/300], Step [400/1875], d_loss: -0.1556, g_loss: -0.5897\n",
      "Epoch [81/300], Step [600/1875], d_loss: -0.1105, g_loss: -0.3982\n",
      "Epoch [81/300], Step [800/1875], d_loss: -0.0683, g_loss: -1.5925\n",
      "Epoch [81/300], Step [1000/1875], d_loss: -0.1755, g_loss: -0.8814\n",
      "Epoch [81/300], Step [1200/1875], d_loss: -0.0688, g_loss: -0.5085\n",
      "Epoch [81/300], Step [1400/1875], d_loss: -0.1429, g_loss: -1.1178\n",
      "Epoch [81/300], Step [1600/1875], d_loss: -0.0390, g_loss: -0.7235\n",
      "Epoch [81/300], Step [1800/1875], d_loss: -0.1051, g_loss: -1.2601\n",
      "Epoch [82/300], Step [200/1875], d_loss: -0.1506, g_loss: -0.6606\n",
      "Epoch [82/300], Step [400/1875], d_loss: -0.1304, g_loss: -2.0669\n",
      "Epoch [82/300], Step [600/1875], d_loss: -0.1357, g_loss: -1.0492\n",
      "Epoch [82/300], Step [800/1875], d_loss: -0.0987, g_loss: -1.7064\n",
      "Epoch [82/300], Step [1000/1875], d_loss: -0.0924, g_loss: -2.0316\n",
      "Epoch [82/300], Step [1200/1875], d_loss: -0.1117, g_loss: -0.7398\n",
      "Epoch [82/300], Step [1400/1875], d_loss: -0.2159, g_loss: -2.4558\n",
      "Epoch [82/300], Step [1600/1875], d_loss: 0.1277, g_loss: -1.0405\n",
      "Epoch [82/300], Step [1800/1875], d_loss: -0.1847, g_loss: 0.0347\n",
      "Epoch [83/300], Step [200/1875], d_loss: 0.0360, g_loss: -1.1609\n",
      "Epoch [83/300], Step [400/1875], d_loss: -0.1467, g_loss: -0.6837\n",
      "Epoch [83/300], Step [600/1875], d_loss: -0.1449, g_loss: -0.9187\n",
      "Epoch [83/300], Step [800/1875], d_loss: -0.0886, g_loss: -0.4415\n",
      "Epoch [83/300], Step [1000/1875], d_loss: -0.2573, g_loss: -1.9428\n",
      "Epoch [83/300], Step [1200/1875], d_loss: -0.0570, g_loss: 0.0978\n",
      "Epoch [83/300], Step [1400/1875], d_loss: -0.0291, g_loss: -1.6879\n",
      "Epoch [83/300], Step [1600/1875], d_loss: -0.1247, g_loss: -0.3869\n",
      "Epoch [83/300], Step [1800/1875], d_loss: -0.1474, g_loss: -1.3537\n",
      "Epoch [84/300], Step [200/1875], d_loss: 0.0673, g_loss: -0.6134\n",
      "Epoch [84/300], Step [400/1875], d_loss: -0.0283, g_loss: 0.3079\n",
      "Epoch [84/300], Step [600/1875], d_loss: 0.0161, g_loss: -0.8686\n",
      "Epoch [84/300], Step [800/1875], d_loss: -0.0037, g_loss: -0.5329\n",
      "Epoch [84/300], Step [1000/1875], d_loss: -0.1093, g_loss: -1.4549\n",
      "Epoch [84/300], Step [1200/1875], d_loss: -0.1273, g_loss: -0.4195\n",
      "Epoch [84/300], Step [1400/1875], d_loss: -0.1235, g_loss: -1.1302\n",
      "Epoch [84/300], Step [1600/1875], d_loss: -0.0649, g_loss: -0.9837\n",
      "Epoch [84/300], Step [1800/1875], d_loss: -0.0353, g_loss: -0.5459\n",
      "Epoch [85/300], Step [200/1875], d_loss: 0.1331, g_loss: -2.5164\n",
      "Epoch [85/300], Step [400/1875], d_loss: -0.0665, g_loss: -0.4657\n",
      "Epoch [85/300], Step [600/1875], d_loss: -0.0955, g_loss: -0.9495\n",
      "Epoch [85/300], Step [800/1875], d_loss: -0.1715, g_loss: -1.6615\n",
      "Epoch [85/300], Step [1000/1875], d_loss: -0.1233, g_loss: -2.3761\n",
      "Epoch [85/300], Step [1200/1875], d_loss: -0.1345, g_loss: -1.8988\n",
      "Epoch [85/300], Step [1400/1875], d_loss: -0.2400, g_loss: 1.6287\n",
      "Epoch [85/300], Step [1600/1875], d_loss: -0.1089, g_loss: -0.6803\n",
      "Epoch [85/300], Step [1800/1875], d_loss: 0.0809, g_loss: 0.0326\n",
      "Epoch [86/300], Step [200/1875], d_loss: -0.2262, g_loss: -1.6718\n",
      "Epoch [86/300], Step [400/1875], d_loss: -0.1486, g_loss: -1.7891\n",
      "Epoch [86/300], Step [600/1875], d_loss: -0.1393, g_loss: 0.6151\n",
      "Epoch [86/300], Step [800/1875], d_loss: -0.1536, g_loss: 0.2337\n",
      "Epoch [86/300], Step [1000/1875], d_loss: 0.0327, g_loss: -0.6589\n",
      "Epoch [86/300], Step [1200/1875], d_loss: -0.0173, g_loss: -2.0926\n",
      "Epoch [86/300], Step [1400/1875], d_loss: -0.0901, g_loss: -1.7329\n",
      "Epoch [86/300], Step [1600/1875], d_loss: -0.1875, g_loss: -1.2759\n",
      "Epoch [86/300], Step [1800/1875], d_loss: -0.0795, g_loss: -1.6485\n",
      "Epoch [87/300], Step [200/1875], d_loss: -0.0253, g_loss: -0.2739\n",
      "Epoch [87/300], Step [400/1875], d_loss: -0.0903, g_loss: -0.1781\n",
      "Epoch [87/300], Step [600/1875], d_loss: -0.1350, g_loss: -1.7635\n",
      "Epoch [87/300], Step [800/1875], d_loss: -0.0610, g_loss: -1.2599\n",
      "Epoch [87/300], Step [1000/1875], d_loss: -0.1470, g_loss: -0.1031\n",
      "Epoch [87/300], Step [1200/1875], d_loss: -0.1403, g_loss: -2.5534\n",
      "Epoch [87/300], Step [1400/1875], d_loss: -0.0718, g_loss: 0.0771\n",
      "Epoch [87/300], Step [1600/1875], d_loss: -0.0583, g_loss: -1.1922\n",
      "Epoch [87/300], Step [1800/1875], d_loss: -0.1218, g_loss: -1.0508\n",
      "Epoch [88/300], Step [200/1875], d_loss: -0.1576, g_loss: -1.1540\n",
      "Epoch [88/300], Step [400/1875], d_loss: -0.1715, g_loss: 0.3514\n",
      "Epoch [88/300], Step [600/1875], d_loss: -0.1486, g_loss: -1.7478\n",
      "Epoch [88/300], Step [800/1875], d_loss: -0.2123, g_loss: -1.7799\n",
      "Epoch [88/300], Step [1000/1875], d_loss: -0.0013, g_loss: -1.1489\n",
      "Epoch [88/300], Step [1200/1875], d_loss: 0.0860, g_loss: -0.9473\n",
      "Epoch [88/300], Step [1400/1875], d_loss: -0.1794, g_loss: -0.8232\n",
      "Epoch [88/300], Step [1600/1875], d_loss: -0.0054, g_loss: -1.5860\n",
      "Epoch [88/300], Step [1800/1875], d_loss: -0.1173, g_loss: -0.2981\n",
      "Epoch [89/300], Step [200/1875], d_loss: -0.0836, g_loss: -1.1417\n",
      "Epoch [89/300], Step [400/1875], d_loss: -0.1397, g_loss: -0.0608\n",
      "Epoch [89/300], Step [600/1875], d_loss: 0.0768, g_loss: -1.3613\n",
      "Epoch [89/300], Step [800/1875], d_loss: -0.1532, g_loss: -0.7502\n",
      "Epoch [89/300], Step [1000/1875], d_loss: -0.1255, g_loss: -2.1201\n",
      "Epoch [89/300], Step [1200/1875], d_loss: -0.1064, g_loss: 0.3313\n",
      "Epoch [89/300], Step [1400/1875], d_loss: -0.1577, g_loss: -0.6032\n",
      "Epoch [89/300], Step [1600/1875], d_loss: -0.0608, g_loss: -1.4059\n",
      "Epoch [89/300], Step [1800/1875], d_loss: -0.2773, g_loss: -3.0881\n",
      "Epoch [90/300], Step [200/1875], d_loss: -0.1141, g_loss: -0.1437\n",
      "Epoch [90/300], Step [400/1875], d_loss: -0.1317, g_loss: -0.4878\n",
      "Epoch [90/300], Step [600/1875], d_loss: 0.2788, g_loss: -0.4716\n",
      "Epoch [90/300], Step [800/1875], d_loss: -0.0920, g_loss: -1.5144\n",
      "Epoch [90/300], Step [1000/1875], d_loss: -0.1635, g_loss: -2.2752\n",
      "Epoch [90/300], Step [1200/1875], d_loss: -0.1088, g_loss: -0.0595\n",
      "Epoch [90/300], Step [1400/1875], d_loss: -0.2207, g_loss: 0.0872\n",
      "Epoch [90/300], Step [1600/1875], d_loss: -0.0221, g_loss: -1.5476\n",
      "Epoch [90/300], Step [1800/1875], d_loss: -0.1442, g_loss: -1.0459\n",
      "Epoch [91/300], Step [200/1875], d_loss: -0.0854, g_loss: 0.5300\n",
      "Epoch [91/300], Step [400/1875], d_loss: -0.1311, g_loss: -0.4564\n",
      "Epoch [91/300], Step [600/1875], d_loss: -0.1950, g_loss: -0.0948\n",
      "Epoch [91/300], Step [800/1875], d_loss: -0.1819, g_loss: -0.1587\n",
      "Epoch [91/300], Step [1000/1875], d_loss: -0.1879, g_loss: -2.6599\n",
      "Epoch [91/300], Step [1200/1875], d_loss: -0.0851, g_loss: -1.1279\n",
      "Epoch [91/300], Step [1400/1875], d_loss: 0.0044, g_loss: -0.2691\n",
      "Epoch [91/300], Step [1600/1875], d_loss: -0.2069, g_loss: -1.7364\n",
      "Epoch [91/300], Step [1800/1875], d_loss: -0.1688, g_loss: -0.0641\n",
      "Epoch [92/300], Step [200/1875], d_loss: -0.2820, g_loss: -2.6651\n",
      "Epoch [92/300], Step [400/1875], d_loss: -0.1675, g_loss: 0.7430\n",
      "Epoch [92/300], Step [600/1875], d_loss: -0.2068, g_loss: -2.3171\n",
      "Epoch [92/300], Step [800/1875], d_loss: -0.1240, g_loss: -0.1872\n",
      "Epoch [92/300], Step [1000/1875], d_loss: -0.1340, g_loss: -1.6501\n",
      "Epoch [92/300], Step [1200/1875], d_loss: 0.0196, g_loss: -0.4795\n",
      "Epoch [92/300], Step [1400/1875], d_loss: -0.0137, g_loss: 0.7608\n",
      "Epoch [92/300], Step [1600/1875], d_loss: 0.0602, g_loss: -0.7514\n",
      "Epoch [92/300], Step [1800/1875], d_loss: -0.0268, g_loss: -0.6651\n",
      "Epoch [93/300], Step [200/1875], d_loss: -0.1348, g_loss: 0.7665\n",
      "Epoch [93/300], Step [400/1875], d_loss: -0.1576, g_loss: -0.6412\n",
      "Epoch [93/300], Step [600/1875], d_loss: 0.0727, g_loss: -1.3498\n",
      "Epoch [93/300], Step [800/1875], d_loss: -0.0894, g_loss: -0.8426\n",
      "Epoch [93/300], Step [1000/1875], d_loss: -0.1787, g_loss: 2.3881\n",
      "Epoch [93/300], Step [1200/1875], d_loss: -0.1694, g_loss: -0.2569\n",
      "Epoch [93/300], Step [1400/1875], d_loss: -0.1205, g_loss: -0.4788\n",
      "Epoch [93/300], Step [1600/1875], d_loss: -0.1862, g_loss: -0.0850\n",
      "Epoch [93/300], Step [1800/1875], d_loss: -0.1262, g_loss: -0.8264\n",
      "Epoch [94/300], Step [200/1875], d_loss: -0.0879, g_loss: -1.3067\n",
      "Epoch [94/300], Step [400/1875], d_loss: -0.1680, g_loss: -1.5510\n",
      "Epoch [94/300], Step [600/1875], d_loss: 0.0582, g_loss: 0.2902\n",
      "Epoch [94/300], Step [800/1875], d_loss: -0.1429, g_loss: -2.0835\n",
      "Epoch [94/300], Step [1000/1875], d_loss: -0.1777, g_loss: -0.6201\n",
      "Epoch [94/300], Step [1200/1875], d_loss: -0.1435, g_loss: 0.2309\n",
      "Epoch [94/300], Step [1400/1875], d_loss: -0.0981, g_loss: -1.1097\n",
      "Epoch [94/300], Step [1600/1875], d_loss: -0.1039, g_loss: -1.2445\n",
      "Epoch [94/300], Step [1800/1875], d_loss: -0.1166, g_loss: -1.2920\n",
      "Epoch [95/300], Step [200/1875], d_loss: -0.1612, g_loss: -2.4766\n",
      "Epoch [95/300], Step [400/1875], d_loss: -0.1202, g_loss: -0.0112\n",
      "Epoch [95/300], Step [600/1875], d_loss: -0.1098, g_loss: -0.8938\n",
      "Epoch [95/300], Step [800/1875], d_loss: -0.1235, g_loss: 0.3827\n",
      "Epoch [95/300], Step [1000/1875], d_loss: -0.1225, g_loss: -1.3248\n",
      "Epoch [95/300], Step [1200/1875], d_loss: -0.2053, g_loss: -1.5438\n",
      "Epoch [95/300], Step [1400/1875], d_loss: -0.1943, g_loss: 0.9865\n",
      "Epoch [95/300], Step [1600/1875], d_loss: -0.1033, g_loss: -0.1279\n",
      "Epoch [95/300], Step [1800/1875], d_loss: -0.0983, g_loss: -1.5978\n",
      "Epoch [96/300], Step [200/1875], d_loss: -0.2415, g_loss: -1.4007\n",
      "Epoch [96/300], Step [400/1875], d_loss: -0.2243, g_loss: -2.8021\n",
      "Epoch [96/300], Step [600/1875], d_loss: 0.0344, g_loss: -0.2986\n",
      "Epoch [96/300], Step [800/1875], d_loss: -0.1516, g_loss: -0.9752\n",
      "Epoch [96/300], Step [1000/1875], d_loss: -0.3552, g_loss: 2.1239\n",
      "Epoch [96/300], Step [1200/1875], d_loss: -0.1669, g_loss: -0.2843\n",
      "Epoch [96/300], Step [1400/1875], d_loss: -0.0266, g_loss: 0.0975\n",
      "Epoch [96/300], Step [1600/1875], d_loss: -0.2107, g_loss: -2.5898\n",
      "Epoch [96/300], Step [1800/1875], d_loss: -0.1702, g_loss: 0.8604\n",
      "Epoch [97/300], Step [200/1875], d_loss: -0.2013, g_loss: 0.7328\n",
      "Epoch [97/300], Step [400/1875], d_loss: -0.1227, g_loss: -2.1247\n",
      "Epoch [97/300], Step [600/1875], d_loss: -0.2238, g_loss: 0.2050\n",
      "Epoch [97/300], Step [800/1875], d_loss: -0.0468, g_loss: -1.4546\n",
      "Epoch [97/300], Step [1000/1875], d_loss: -0.1103, g_loss: -0.4018\n",
      "Epoch [97/300], Step [1200/1875], d_loss: -0.1075, g_loss: -1.9717\n",
      "Epoch [97/300], Step [1400/1875], d_loss: -0.0966, g_loss: -0.5993\n",
      "Epoch [97/300], Step [1600/1875], d_loss: -0.1547, g_loss: -1.2069\n",
      "Epoch [97/300], Step [1800/1875], d_loss: -0.1139, g_loss: 0.7840\n",
      "Epoch [98/300], Step [200/1875], d_loss: -0.0556, g_loss: -0.4045\n",
      "Epoch [98/300], Step [400/1875], d_loss: -0.1481, g_loss: -0.1089\n",
      "Epoch [98/300], Step [600/1875], d_loss: -0.1995, g_loss: -1.6095\n",
      "Epoch [98/300], Step [800/1875], d_loss: -0.1608, g_loss: -1.2192\n",
      "Epoch [98/300], Step [1000/1875], d_loss: -0.1696, g_loss: 0.1243\n",
      "Epoch [98/300], Step [1200/1875], d_loss: -0.1260, g_loss: -1.3330\n",
      "Epoch [98/300], Step [1400/1875], d_loss: -0.0599, g_loss: -0.1652\n",
      "Epoch [98/300], Step [1600/1875], d_loss: 0.0766, g_loss: -2.2666\n",
      "Epoch [98/300], Step [1800/1875], d_loss: -0.1705, g_loss: 0.8263\n",
      "Epoch [99/300], Step [200/1875], d_loss: 0.0105, g_loss: -1.0477\n",
      "Epoch [99/300], Step [400/1875], d_loss: -0.1712, g_loss: -0.7247\n",
      "Epoch [99/300], Step [600/1875], d_loss: -0.1276, g_loss: 0.0947\n",
      "Epoch [99/300], Step [800/1875], d_loss: -0.1590, g_loss: -1.5954\n",
      "Epoch [99/300], Step [1000/1875], d_loss: -0.1602, g_loss: 0.0515\n",
      "Epoch [99/300], Step [1200/1875], d_loss: -0.0738, g_loss: 0.1322\n",
      "Epoch [99/300], Step [1400/1875], d_loss: -0.0130, g_loss: -2.4847\n",
      "Epoch [99/300], Step [1600/1875], d_loss: -0.0789, g_loss: -0.2984\n",
      "Epoch [99/300], Step [1800/1875], d_loss: -0.0962, g_loss: 0.0520\n",
      "Epoch [100/300], Step [200/1875], d_loss: -0.0505, g_loss: -1.4684\n",
      "Epoch [100/300], Step [400/1875], d_loss: -0.1879, g_loss: -0.7978\n",
      "Epoch [100/300], Step [600/1875], d_loss: -0.0854, g_loss: -0.5692\n",
      "Epoch [100/300], Step [800/1875], d_loss: -0.0684, g_loss: -1.4801\n",
      "Epoch [100/300], Step [1000/1875], d_loss: -0.1267, g_loss: -1.3936\n",
      "Epoch [100/300], Step [1200/1875], d_loss: -0.0053, g_loss: -1.7399\n",
      "Epoch [100/300], Step [1400/1875], d_loss: 0.0203, g_loss: 0.5926\n",
      "Epoch [100/300], Step [1600/1875], d_loss: -0.1064, g_loss: -1.4347\n",
      "Epoch [100/300], Step [1800/1875], d_loss: -0.1103, g_loss: -1.4889\n",
      "Epoch [101/300], Step [200/1875], d_loss: -0.1229, g_loss: 0.0770\n",
      "Epoch [101/300], Step [400/1875], d_loss: -0.1875, g_loss: 0.2182\n",
      "Epoch [101/300], Step [600/1875], d_loss: -0.1204, g_loss: -0.7025\n",
      "Epoch [101/300], Step [800/1875], d_loss: -0.2129, g_loss: -2.0847\n",
      "Epoch [101/300], Step [1000/1875], d_loss: -0.0642, g_loss: -1.1075\n",
      "Epoch [101/300], Step [1200/1875], d_loss: -0.0021, g_loss: 0.7732\n",
      "Epoch [101/300], Step [1400/1875], d_loss: -0.0718, g_loss: -1.6272\n",
      "Epoch [101/300], Step [1600/1875], d_loss: -0.0839, g_loss: -1.2043\n",
      "Epoch [101/300], Step [1800/1875], d_loss: -0.0713, g_loss: -0.3000\n",
      "Epoch [102/300], Step [200/1875], d_loss: -0.0238, g_loss: -2.6368\n",
      "Epoch [102/300], Step [400/1875], d_loss: -0.2065, g_loss: -0.8697\n",
      "Epoch [102/300], Step [600/1875], d_loss: -0.1615, g_loss: -1.3458\n",
      "Epoch [102/300], Step [800/1875], d_loss: -0.1579, g_loss: 0.8547\n",
      "Epoch [102/300], Step [1000/1875], d_loss: -0.0433, g_loss: -1.2247\n",
      "Epoch [102/300], Step [1200/1875], d_loss: -0.0585, g_loss: 0.0373\n",
      "Epoch [102/300], Step [1400/1875], d_loss: -0.0349, g_loss: -0.5168\n",
      "Epoch [102/300], Step [1600/1875], d_loss: -0.1015, g_loss: -0.9715\n",
      "Epoch [102/300], Step [1800/1875], d_loss: -0.0788, g_loss: -0.9820\n",
      "Epoch [103/300], Step [200/1875], d_loss: -0.0880, g_loss: -2.5163\n",
      "Epoch [103/300], Step [400/1875], d_loss: -0.0071, g_loss: -0.9120\n",
      "Epoch [103/300], Step [600/1875], d_loss: -0.1499, g_loss: -0.6474\n",
      "Epoch [103/300], Step [800/1875], d_loss: -0.0461, g_loss: -0.6365\n",
      "Epoch [103/300], Step [1000/1875], d_loss: -0.0786, g_loss: -0.1701\n",
      "Epoch [103/300], Step [1200/1875], d_loss: -0.0627, g_loss: -0.1385\n",
      "Epoch [103/300], Step [1400/1875], d_loss: -0.0918, g_loss: 0.2216\n",
      "Epoch [103/300], Step [1600/1875], d_loss: -0.1177, g_loss: -0.7320\n",
      "Epoch [103/300], Step [1800/1875], d_loss: -0.1243, g_loss: -1.8185\n",
      "Epoch [104/300], Step [200/1875], d_loss: -0.1644, g_loss: -1.4551\n",
      "Epoch [104/300], Step [400/1875], d_loss: -0.1553, g_loss: -1.2828\n",
      "Epoch [104/300], Step [600/1875], d_loss: -0.0836, g_loss: -2.2718\n",
      "Epoch [104/300], Step [800/1875], d_loss: -0.1557, g_loss: -1.2363\n",
      "Epoch [104/300], Step [1000/1875], d_loss: -0.1305, g_loss: -1.6254\n",
      "Epoch [104/300], Step [1200/1875], d_loss: -0.1413, g_loss: -3.4014\n",
      "Epoch [104/300], Step [1400/1875], d_loss: -0.1285, g_loss: -1.2951\n",
      "Epoch [104/300], Step [1600/1875], d_loss: -0.0704, g_loss: -1.8138\n",
      "Epoch [104/300], Step [1800/1875], d_loss: -0.1750, g_loss: -0.0964\n",
      "Epoch [105/300], Step [200/1875], d_loss: -0.0302, g_loss: -2.1281\n",
      "Epoch [105/300], Step [400/1875], d_loss: -0.2129, g_loss: 0.7159\n",
      "Epoch [105/300], Step [600/1875], d_loss: -0.0670, g_loss: -1.1967\n",
      "Epoch [105/300], Step [800/1875], d_loss: -0.0110, g_loss: 0.1844\n",
      "Epoch [105/300], Step [1000/1875], d_loss: -0.1228, g_loss: 0.8045\n",
      "Epoch [105/300], Step [1200/1875], d_loss: -0.2295, g_loss: -0.4182\n",
      "Epoch [105/300], Step [1400/1875], d_loss: -0.0550, g_loss: -0.3726\n",
      "Epoch [105/300], Step [1600/1875], d_loss: -0.1201, g_loss: -1.6004\n",
      "Epoch [105/300], Step [1800/1875], d_loss: -0.0207, g_loss: -1.3206\n",
      "Epoch [106/300], Step [200/1875], d_loss: -0.0963, g_loss: -1.8085\n",
      "Epoch [106/300], Step [400/1875], d_loss: -0.1586, g_loss: -1.3464\n",
      "Epoch [106/300], Step [600/1875], d_loss: -0.0655, g_loss: -0.4351\n",
      "Epoch [106/300], Step [800/1875], d_loss: -0.0078, g_loss: -1.3012\n",
      "Epoch [106/300], Step [1000/1875], d_loss: -0.1205, g_loss: -2.2981\n",
      "Epoch [106/300], Step [1200/1875], d_loss: -0.1318, g_loss: -1.2868\n",
      "Epoch [106/300], Step [1400/1875], d_loss: -0.1021, g_loss: -0.6808\n",
      "Epoch [106/300], Step [1600/1875], d_loss: -0.1149, g_loss: -1.2688\n",
      "Epoch [106/300], Step [1800/1875], d_loss: -0.0989, g_loss: -0.1638\n",
      "Epoch [107/300], Step [200/1875], d_loss: -0.0285, g_loss: -0.0215\n",
      "Epoch [107/300], Step [400/1875], d_loss: -0.1679, g_loss: 0.0021\n",
      "Epoch [107/300], Step [600/1875], d_loss: -0.1218, g_loss: -1.1273\n",
      "Epoch [107/300], Step [800/1875], d_loss: -0.1676, g_loss: -0.3149\n",
      "Epoch [107/300], Step [1000/1875], d_loss: -0.1058, g_loss: 0.4544\n",
      "Epoch [107/300], Step [1200/1875], d_loss: 0.0197, g_loss: -1.1066\n",
      "Epoch [107/300], Step [1400/1875], d_loss: -0.1792, g_loss: 0.4289\n",
      "Epoch [107/300], Step [1600/1875], d_loss: -0.0388, g_loss: -1.0782\n",
      "Epoch [107/300], Step [1800/1875], d_loss: -0.2919, g_loss: 0.1184\n",
      "Epoch [108/300], Step [200/1875], d_loss: -0.1812, g_loss: -2.3494\n",
      "Epoch [108/300], Step [400/1875], d_loss: -0.0246, g_loss: -2.1018\n",
      "Epoch [108/300], Step [600/1875], d_loss: -0.1771, g_loss: -1.1840\n",
      "Epoch [108/300], Step [800/1875], d_loss: -0.1244, g_loss: -2.2868\n",
      "Epoch [108/300], Step [1000/1875], d_loss: -0.1095, g_loss: -1.6191\n",
      "Epoch [108/300], Step [1200/1875], d_loss: -0.0027, g_loss: 0.0545\n",
      "Epoch [108/300], Step [1400/1875], d_loss: -0.0685, g_loss: -0.2264\n",
      "Epoch [108/300], Step [1600/1875], d_loss: -0.0879, g_loss: -1.4508\n",
      "Epoch [108/300], Step [1800/1875], d_loss: -0.1282, g_loss: -0.1566\n",
      "Epoch [109/300], Step [200/1875], d_loss: -0.1626, g_loss: -1.3427\n",
      "Epoch [109/300], Step [400/1875], d_loss: -0.0120, g_loss: -0.9235\n",
      "Epoch [109/300], Step [600/1875], d_loss: -0.1173, g_loss: -1.1011\n",
      "Epoch [109/300], Step [800/1875], d_loss: -0.0624, g_loss: -0.3833\n",
      "Epoch [109/300], Step [1000/1875], d_loss: -0.1964, g_loss: 0.0791\n",
      "Epoch [109/300], Step [1200/1875], d_loss: -0.1409, g_loss: -2.5545\n",
      "Epoch [109/300], Step [1400/1875], d_loss: -0.2103, g_loss: -2.1784\n",
      "Epoch [109/300], Step [1600/1875], d_loss: -0.1198, g_loss: -2.3717\n",
      "Epoch [109/300], Step [1800/1875], d_loss: -0.2317, g_loss: -0.5944\n",
      "Epoch [110/300], Step [200/1875], d_loss: 0.0609, g_loss: -1.4594\n",
      "Epoch [110/300], Step [400/1875], d_loss: -0.1585, g_loss: 0.6493\n",
      "Epoch [110/300], Step [600/1875], d_loss: -0.0717, g_loss: -1.0084\n",
      "Epoch [110/300], Step [800/1875], d_loss: -0.0358, g_loss: -0.5057\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now().strftime(\"%Y%m%d_%Hh%Mm%Ss\")\n",
    "total_step = len(data_loader)\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    for i, (images, _) in enumerate(data_loader):\n",
    "        \n",
    "        # 1. Send image to device\n",
    "        images = Variable(images, requires_grad = True).cuda()\n",
    "        \n",
    "        \"\"\"\n",
    "        PART 1: TRAIN THE CRITIC\n",
    "        \"\"\"\n",
    "        \n",
    "        # 2. Compute mean of critic decisions using real images\n",
    "        outputs_real = f(images)\n",
    "        \n",
    "        # 2.bis. Compute mean of critic decisions using fake images\n",
    "        z = torch.randn(batch_size, latent_size, 3, 3).to(device)\n",
    "        z = Variable(z)\n",
    "        fake_images = G(z)\n",
    "        outputs_fake = f(fake_images)\n",
    "        \n",
    "        # 3. Compute gradient regularization\n",
    "        real_grad_out = Variable(Tensor(images.size(0), 1).fill_(0.9), requires_grad = False).to(device)\n",
    "        real_grad = autograd.grad(outputs_real, images, real_grad_out, create_graph = True, \\\n",
    "                                  retain_graph = True, only_inputs = True)[0]\n",
    "        real_grad_norm = real_grad.view(real_grad.size(0), -1).pow(2).sum(1)**3\n",
    "        fake_grad_out = Variable(Tensor(fake_images.size(0), 1).fill_(0.9), requires_grad = False).to(device)\n",
    "        fake_grad = autograd.grad(outputs_fake, fake_images, fake_grad_out, create_graph = True, \\\n",
    "                                  retain_graph = True, only_inputs = True)[0]\n",
    "        fake_grad_norm = fake_grad.view(fake_grad.size(0), -1).pow(2).sum(1)**3\n",
    "        reg_term = torch.mean(real_grad_norm + fake_grad_norm)\n",
    "        \n",
    "        # 4. Backprop and optimize for f\n",
    "        # Loss is simply the difference between means, plus regularization term\n",
    "        # Remember to reset gradients for both optimizers!\n",
    "        d_loss = -torch.mean(outputs_real) + torch.mean(outputs_fake) + reg_term\n",
    "        d_optimizer.zero_grad()\n",
    "        g_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        # 4.bis. Optional, weight clipping on critic\n",
    "        # (Mentioned in WGAN paper)\n",
    "        for p in f.parameters():\n",
    "            p.data.clamp_(-0.01, 0.01)\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        PART 2: TRAIN THE GENERATOR\n",
    "        \"\"\"\n",
    "\n",
    "        # for _ in range(gen_train_no):\n",
    "        # 5. Generate fresh noise samples and produce fake images\n",
    "        z = torch.randn(batch_size, latent_size, 3, 3).cuda()\n",
    "        z = Variable(z)\n",
    "        fake_images = G(z)\n",
    "        outputs = f(fake_images)\n",
    "        \n",
    "        # 6. Loss for G\n",
    "        g_loss = - torch.mean(outputs)\n",
    "        \n",
    "        # 7. Backprop and optimize G\n",
    "        # Remember to reset gradients for both optimizers!\n",
    "        d_optimizer.zero_grad()\n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        PART 3: UPDATE STATISTICS FOR VISUALIZATION LATER\n",
    "        \"\"\"\n",
    "        \n",
    "        # 8. Update the losses and scores for mini-batches\n",
    "        d_losses[epoch] = d_losses[epoch]*(i/(i+1.)) \\\n",
    "            + d_loss.item()*(1./(i+1.))\n",
    "        g_losses[epoch] = g_losses[epoch]*(i/(i+1.)) \\\n",
    "            + g_loss.item()*(1./(i+1.))\n",
    "        \n",
    "        # 9. Display\n",
    "        if (i+1) % 200 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}' \n",
    "                  .format(epoch, num_epochs, i+1, total_step, d_loss.item(), g_loss.item()))\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        # save fake_images\n",
    "        fake_images = fake_images.cpu().detach().numpy().reshape(fake_images.shape[0], 28, 28)\n",
    "        fig, ax = plt.subplots(nrows=img_grid_row, ncols=img_grid_col, figsize=(35, 20))\n",
    "        for idx, img in enumerate(fake_images):\n",
    "            row_idx = idx // img_grid_col\n",
    "            col_idx = idx % img_grid_col\n",
    "            ax[row_idx][col_idx].imshow(img)\n",
    "        plt.savefig(f\"generated_imgs/{start_time}_ep{epoch}_samples.png\")\n",
    "\n",
    "        # Save models\n",
    "        torch.save(f.state_dict(), f\"saved_models/{start_time}_ep{epoch}_critic.pth\")\n",
    "        torch.save(G.state_dict(), f\"saved_models/{start_time}_ep{epoch}_generator.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Generator(\n  (transconv1): ConvTranspose2d(64, 64, kernel_size=(9, 9), stride=(1, 1))\n  (transconv2): ConvTranspose2d(64, 64, kernel_size=(9, 9), stride=(1, 1))\n  (transconv3): ConvTranspose2d(64, 1, kernel_size=(10, 10), stride=(1, 1))\n  (leaky_relu): LeakyReLU(negative_slope=0.01)\n  (tanh): Tanh()\n)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load trained models\n",
    "# f.load_state_dict(torch.load(\"critic.pth\"))\n",
    "# f.eval()\n",
    "G.load_state_dict(torch.load(\"saved_models/20210416_08h13m02s_ep40_generator.pth\"))\n",
    "G.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "# Display losses for both the generator and discriminator\n",
    "plt.figure()\n",
    "plt.plot(range(1, epoch + 1), d_losses[:epoch], label = 'd loss')\n",
    "plt.plot(range(1, epoch + 1), g_losses[:epoch], label = 'g loss')    \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Generate a few fake samples (5 of them) for visualization\n",
    "n_samples = 5\n",
    "z = torch.randn(n_samples, latent_size, 3, 3).cuda()\n",
    "z = Variable(z)\n",
    "fake_images = G(z)\n",
    "fake_images = fake_images.cpu().detach().numpy().reshape(n_samples, 28, 28)\n",
    "print(fake_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display\n",
    "plt.figure()\n",
    "plt.imshow(fake_images[0])\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.imshow(fake_images[1])\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.imshow(fake_images[2])\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.imshow(fake_images[3])\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.imshow(fake_images[4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 1800x360 with 5 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=n_samples, figsize=(25, 5))\n",
    "for i in range(n_samples):\n",
    "    ax[i].imshow(fake_images[i])\n",
    "plt.savefig('20210416_08h13m02s_ep60_generator.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions and expected answers for the report\n",
    "\n",
    "1. Copy and paste the code for your Critic class. Briefly explain your choice of architecture.\n",
    "\n",
    "2. Copy and paste the code for your Generator class. Briefly explain your choice of architecture.\n",
    "\n",
    "3. For how many iterations did you have to train when using Wasserstein with Conv/TransposeConv layers to get plausible images from the generator? Is it training faster than the Fully Connected Wasserstein/Vanilla GAN?\n",
    "\n",
    "4. Display some samples generated by your trained generator. Do they look plausible?\n",
    "\n",
    "5. Let us assume we use Conv2d layers in the Critic. We do NOT use Transposed Conv2d layers, but only Fully Connected layers in the Generator. Would the GAN still be able to train both models or would it encounter difficulties? Discuss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('dl': conda)",
   "name": "python388jvsc74a57bd09bdb71cc335c0ff538946176ad679f1f73afaf0a37ebb6555520787290f7e82f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}